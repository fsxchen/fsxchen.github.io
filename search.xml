<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hexo、GitPage书写博客]]></title>
    <url>%2F2017%2F05%2F11%2FMISC%2FHexo%E3%80%81GitPage%E4%B9%A6%E5%86%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[使用Hexo、GitPage书写博客Hexo、GitPage​ 以前使用的静态博客工具是Pelican，本来以为有python的基础会好点，然而发现博客和工具的语言没关系，主要还是看方便和外观以及编译的速度，最终了决定选择了HEXO这个工具，从之前的Pelican迁移过来还是很方便，只需要把以前的*.md放到_posts目录中就好了。相关的基础知识就不多说了。 图片上传​ 关于图片的问题，有多种解决方案。关于图片，一只很欣赏像马克飞象的从剪贴板能够直接上传。使用Atom编辑器。 方案一 使用本地图片​ gitpages本省有300M的空间，如果图片数据不是很大，那么放在本地是完全足够的。如下配置即可。 Atom插件markclip安装 这个插件能够处理剪贴板中的图片文件，将图片存放在和文档名称相同的目录中。 HEXO的插件hexo-asset-image 首先确认 _config.yml 中有 post_asset_folder:true 然后安装该插件 1npm install https://github.com/CodeFalling/hexo-asset-image --save 方案二 使用七牛云 Atom插件qiniu-uploader和markdown-assistant 申请APP Key，以及相关的配置就不多说了，在这个过程中，由于zone.js中有一个实用了异步http请求，导致了一个错误，在issus中有相关的解决办法。 Markdown书写处理工具​ 如果图片比较多，那么Atom结合前面说的插件、非常给力。另外推介Typora工具来写，支持图片的拖拽。更给力的是，将Markdown导出非常给力。 Next主题​ 这个主题是相当棒的，本身集成了很多插件，比如Mathjax，搜索，打赏、评论等功能，只需要简单的修改就可以打开相关的功能。 ​ Next官网 发布到coding.net​ 和github类似，也可以同步发布到coding.net上，在国内访问还是coding会比较快。只需要在coding上创建一个项目，该项目的名字和用户名必须一致（不然无法加载静态文件）。相关配置如下： 123456deploy: type: git repository: github: https://github.com/username/username.github.io.git coding: https://git.coding.net/username/username.git branch: master]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>HEXO</tag>
        <tag>GitPages</tag>
        <tag>Coding Pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主成分析(PCA)]]></title>
    <url>%2F2017%2F05%2F11%2Fmachinelearning%2F%E4%B8%BB%E6%88%90%E5%88%86%E6%9E%90-PCA%2F</url>
    <content type="text"><![CDATA[主成分析（PCA）一套能够适用于各种训练的数据处理方法 ex: 数据的维度 PCA，将数据的中心作为新的坐标轴，并且旋转X、Y轴]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习]]></title>
    <url>%2F2017%2F05%2F04%2Fmachinelearning%2F2017_05_04_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[深度学习Logistic 函数​ Logistic函数或Logistic曲线是一种常见的S形函数，它是皮埃尔·弗朗索瓦·韦吕勒在1844或1845年在研究它与人口增长的关系时命名的。广义Logistic曲线可以模仿一些情况人口增长（P）的S形曲线。起初阶段大致是指数增长；然后随着开始变得饱和，增加变慢；最后，达到成熟时增加停止。[1] 很像一个“S”型吧，所以又叫 sigmoid曲线（S型曲线）。$$y=\sigma(z)$$$\sigma$ 的定义为$$\sigma={1\over 1+e^{-z}}$$python实现Logistic函数 123456789101112131415import numpy as npimport matplotlib.pyplot as pltdef logistic(z): return 1 / (1 + np.exp(-z))# Plot the logistic functionz = np.linspace(-6,6,100)plt.plot(z, logistic(z), &apos;b-&apos;)plt.xlabel(&apos;$z$&apos;, fontsize=15)plt.ylabel(&apos;$\sigma(z)$&apos;, fontsize=15)plt.title(&apos;logistic function&apos;)plt.grid()plt.show() Logistic函数的导数12345678910def logistic_derivative(z): return logistic(z) * (1 - logistic(z))# Plot the derivative of the logistic functionz = np.linspace(-6,6,100)plt.plot(z, logistic_derivative(z), &apos;r-&apos;)plt.xlabel(&apos;$z$&apos;, fontsize=15)plt.ylabel(&apos;$\\frac&#123;\\partial \\sigma(z)&#125;&#123;\\partial z&#125;$&apos;, fontsize=15)plt.title(&apos;derivative of the logistic function&apos;)plt.grid()plt.show() Logistic回归​ logistic回归是一种广义线性回归（generalized linear model），因此与多重线性回归分析有很多相同之处。它们的模型形式基本上相同，都具有 $w‘x+b$，其中w和b是待求参数，其区别在于他们的因变量不同，多重线性回归直接将w’x+b作为因变量，即y =w‘x+b，而logistic回归则通过函数L将w‘x+b对应一个隐状态p，p =L(w‘x+b),然后根据p 与1-p的大小决定因变量的值。如果L是logistic函数，就是logistic回归，如果L是多项式函数就是多项式回归。 训练一个Logistic回归训练器12345678910111213141516171819202122&quot;&quot;&quot;Softmax.&quot;&quot;&quot;scores = [3.0, 1.0, 0.2]import numpy as npdef softmax(x): &quot;&quot;&quot;Compute softmax values for each sets of scores in x.&quot;&quot;&quot; pass # TODO: Compute and return softmax(x) return np.exp(x) / np.sum(np.exp(x), axis=0)print(softmax(scores))# Plot softmax curvesimport matplotlib.pyplot as pltx = np.arange(-2.0, 6.0, 0.1)scores = np.vstack([x, np.ones_like(x), 0.2 * np.ones_like(x)])plt.plot(x, softmax(scores).T, linewidth=2)plt.show() 训练集合]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征选择]]></title>
    <url>%2F2017%2F05%2F04%2Fmachinelearning%2F2017_05_04_%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[特征的选择 直觉 代码找出特征 可视化 重复 去除特征特征不等于信息正则化lasso回归能够将不太影响分类的特征的权重设置为0]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本学习]]></title>
    <url>%2F2017%2F05%2F04%2Fmachinelearning%2F2017_05_04_%E6%96%87%E6%9C%AC%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[文本学习词袋每个词的频率 词袋属性 无序 长词 复合词 sklearn 词袋低信息量词停词词干提取 词干提取算法（STEMMER） IF-IDFIDF：逆向文件频率 实际上就是IF*IDF 更注重于罕见的词汇！ TfidfVectorizer参数 max_df，0.5，如果在%50的文档中出现了这个词，tfidf就会删除这个词]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征缩放]]></title>
    <url>%2F2017%2F05%2F04%2Fmachinelearning%2F2017_05_04_%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%2F</url>
    <content type="text"><![CDATA[特征缩放$$x’=（x-x{min}）/（x{max-}x_{min}）$$ sklearn MinMaxScaler]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚类]]></title>
    <url>%2F2017%2F05%2F03%2Fmachinelearning%2F2017_05_03_%E8%81%9A%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[聚类非监督学习降维K均值聚类（K-MEANSs）画出聚类的中心 分配 优化 sklearn clusterK均值聚类的局限 对于同意的一个集合，相同的聚类中心，得出的结果不一定相投]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常值处理]]></title>
    <url>%2F2017%2F05%2F03%2Fmachinelearning%2F2017_05_03_%E5%BC%82%E5%B8%B8%E5%80%BC%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[异常值的处理异常值的产生 传感器错误 录入错误 异常事件 异常值处理 处理流程 训练数据集 去掉%10的数据 再次训练 重复第二部，去掉与之前的%10的数据 应用欺诈检测]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读《聪明人用方格笔记本》]]></title>
    <url>%2F2017%2F05%2F03%2Fread%2F2017_05_03_%E8%AF%BB%E3%80%8A%E8%81%AA%E6%98%8E%E4%BA%BA%E7%94%A8%E6%96%B9%E6%A0%BC%E7%AC%94%E8%AE%B0%E6%9C%AC%E3%80%8B%2F</url>
    <content type="text"><![CDATA[读《聪明人用方格笔记本》笔记三法则 使用方格笔记 标出题目 用三分法记录 事实 解释 行动 使用方格笔记本 行首对齐 在行首两三个字的地方写小标题 在比小标题往后两三个字的地方写内容 项目改变时空一行 注意流出空隙，留出进行信息整理的空间 学习中最重要的是什么？ “尽可能多地往脑子里塞东西” “不怎么往脑子里塞东西” 一种从有到无的境界 框架=“整理思路的书架” 人容易被“框架”左右的生物 黄金三分法康奈尔笔记本分为（板书（Note）、发现点（Queue）、总结（summary）） 麦肯锡的“空-雨-伞”横向使用A4像报纸标出题目一页一主题10000张纸法则出自于咨询公司 学习笔记本 记忆性笔记本 思考性笔记本 传达性笔记本 使用空白一秒从“看黑板-记笔记”到“看黑板-放到脑袋-记笔记” 两页一主题将A4或者B5作为一页。 或者直接横向使用 驾驭两页之间的中部区域思维不应该因为笔记本的页面限制而被限制 善于发现能够进步？只有进一步的行动才能进步，将“发现”转变为“故事” 逻辑连接词 使用自己的逻辑连词词 三种箭头 展开箭头 总结箭头 强调箭头 总结写解决问题的要点工作笔记本目的是舍弃秘术是整理整理术和收拾法的关键就是将“舍弃”发挥到极致。 提问力等于咨询力提案笔记本]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回归]]></title>
    <url>%2F2017%2F04%2F28%2Fmachinelearning%2F2017_04_28_%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[回归连续监督学习 连续输出和离散输出的区别 这里的连续主要是指输出是连续的 回归线性方程 slope：斜率intercept：截距 斜率和截距斜率越大，上升越快 Sklearn中的线形拟合123456&gt;&gt;&gt; from sklearn import linear_model&gt;&gt;&gt; reg = linear_model.LinearRegression()&gt;&gt;&gt; reg.fit ([[0, 0], [1, 1], [2, 2]], [0, 1, 2])LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)&gt;&gt;&gt; reg.coef_array([ 0.5, 0.5]) 线性回归误差使误差有最小值。 最小二乘法（OLS）sklearn中的线性拟合即使用的是该方法 12345678910111213141516171819202122232425import numpy as npimport matplotlib.pyplot as pltdots = np.array([[1,6], [2,5], [3,7], [4,10], [5, 12]])X = dots[:, 0]Y = dots[:, 1]plt.scatter(X, Y, color = &quot;b&quot;, label=&quot;fast&quot;)def nihe(k, x, b): return k*x + b#a0 = （∑Yi) / n - a1（∑Xi) / n （式1-8)#a1 = [n∑Xi Yi - （∑Xi ∑Yi)] / [n∑Xi2 - （∑Xi)2 )] （式1-9)n = dots.shape[0]a1 = (n*sum(X*Y) - sum(X)*sum(Y)) / (n*sum(X**2)-(sum(X)**2))a0 = sum(Y)/n - a1*(sum(X))/nprint(a0, a1)R_Y = [nihe(a1, x, a0) for x in X]plt.plot(X, R_Y)plt.show() 使用平方误差和来评估拟合的效果？ ​ 如上图所示，如果只是使用绝对值，那么途中的3种拟合方式没有什么区别，然而如果使用平方的方式，只有中间的误差是最小的。 使用平方误差和的方式的不足只处 R平方指标R平方指标弥补了平方误差和的不足之处。 梯度下降法什么数据适用于线性回归线性的，可以拟合成$$y = ax + b$$ 回归于分类的比较 比较 监督分类 回归 输出类型 离散（类型标签） 连续（数字） 目的 找到决策边界 最优拟合线 评估指标 准确率 R平方值 多变量（多元）回归（MULTI-VARIATE REGRESSION)]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据以及数据的处理]]></title>
    <url>%2F2017%2F04%2F27%2Fmachinelearning%2F2017_04_27_%E6%95%B0%E6%8D%AE%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[机器学习中的数据处理数据的类型 数值类型 eg：薪水、年龄、评分 类别变量 eg：职位 时间序列 时间戳 文本数据 邮件类容]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支持向量机]]></title>
    <url>%2F2017%2F04%2F25%2Fmachinelearning%2F2017_04_25_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[支持向量机（SVM）sklearn SVM分类SVC的参数C： kernel： 过度拟合]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朴素贝叶斯]]></title>
    <url>%2F2017%2F04%2F25%2Fmachinelearning%2F2017_04_25_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[贝叶斯算法sklearn 贝叶斯分类123456789from sklearn.naive_bayes import GaussianNBfrom sklearn.metrics import accuracy_scoreclf = GaussianNB()# print(labels_train)clf.fit(features_train, labels_train)pred = clf.predict(features_test)accuracy = accuracy_score(pred, labels_test)print(&quot;准确率:%f&quot;,accuracy)]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP首部详解]]></title>
    <url>%2F2016%2F12%2F26%2Flinuxtcp%2F2016_12_26_ip%E9%A6%96%E9%83%A8%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[IP地址首部]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>tcp/ip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arp的帧格式]]></title>
    <url>%2F2016%2F12%2F19%2Flinuxtcp%2F2016_12_19_arp%E7%9A%84%E5%B8%A7%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[arp的帧格式以及arp举例arp的帧和以太网帧格式对比以太网的帧结构 字段 字段长度（字节） 目的 目的地址（DST） 6 目的地址 源地址（SRC） 6 源地址 长度或者类型 2 长度或者类型 硬件类型 2 指明了发送方想知道的硬件接口类型，以太网的值为1 协议类型 2 指明了发送方提供的高层协议类型，IP为0800（16进制）； 硬件的长度 1 指明了硬件地址长度，这样ARP报文就可以在任意硬件和任意协议的网络中使用 协议的长度 1 指明了高层协议地址的长度，这样ARP报文就可以在任意硬件和任意协议的网络中使用 操作类型 2 用来表示这个报文的类型，ARP请求为1，ARP响应为2，RARP请求为3，RARP响应为4 发送方的硬件地址 6 发送放的硬件地址 发送放的协议地址 4 发送方的协议地址，eg. IPv 目标的硬件地址 6 目标的硬件地址 目标的协议地址 4 目标的协议地址 arp举例正常的访问1➜ ~ sudo tcpdump -e arp 输出：123456789tcpdump: data link type PKTAPtcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on pktap, link-type PKTAP (Packet Tap), capture size 262144 bytes21:14:28.443833 94:77:2b:88:80:6e (oui Unknown) &gt; 70:71:bc:79:ae:a4 (oui Unknown), ethertype ARP (0x0806), length 42: Request who-has 192.168.3.5 tell 192.168.3.1, length 2821:14:28.443853 70:71:bc:79:ae:a4 (oui Unknown) &gt; 94:77:2b:88:80:6e (oui Unknown), ethertype ARP (0x0806), length 42: Reply 192.168.3.5 is-at 70:71:bc:79:ae:a4 (oui Unknown), length 2821:14:36.448013 94:77:2b:88:80:6e (oui Unknown) &gt; Broadcast, ethertype ARP (0x0806), length 60: Request who-has 192.168.3.71 tell 192.168.3.1, length 4621:14:43.923325 dc:f0:90:87:22:bb (oui Unknown) &gt; Broadcast, ethertype ARP (0x0806), length 42: Request who-has 192.168.3.3 tell 192.168.3.86, length 2821:14:48.121289 e8:03:9a:cd:72:c8 (oui Unknown) &gt; Broadcast, ethertype ARP (0x0806), length 42: Request who-has 192.168.3.65 tell 192.168.3.62, length 2821:14:48.122152 02:22:6c:06:8f:d4 (oui Unknown) &gt; Broadcast, ethertype ARP (0x0806), length 42: Request who-has 192.168.3.62 tell 192.168.3.65, length 28 访问地址不存在arp欺骗]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个请求的举例]]></title>
    <url>%2F2016%2F12%2F19%2Flinuxtcp%2F2016_12_19_%E4%B8%80%E4%B8%AA%E8%AF%B7%E6%B1%82%E7%9A%84%E4%B8%BE%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[以太网中的请求说明 当再浏览器中输入http://10.0.0.1,回发生如下事情。 1、浏览器回解析URL，会得到IP地址10.0.0.1。 2、该应用回使用TCP协议去连接10.0.0.1。 3、TCP试图给10.0.0.1发送一个报文。 4、因为10.0.0.1是再局域网中，所以直接通过网络接口发出。 5、由于再以太网中，那么必须把32位的地址转换成48位的网络地址，这个时候就需要arp地址的功能，把逻辑上的IP地址转换位48位的物理地址，这也是arp协议的功能。 6、这个时候，arp发送一份广播包，告诉局域网内的所有的主机 7、目标主机收到arp报文之后，就会发出一个响应的arp，这个响应中包含了硬件地址和IP地址。 8、收到arp应答后，使用arp进行请求–应答交互的IP数据包就可以传送了。 9、发送IP数据到目的主机]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太网的帧结构]]></title>
    <url>%2F2016%2F12%2F08%2Flinuxtcp%2F2016_12_08_%E4%BB%A5%E5%A4%AA%E7%BD%91%E7%9A%84%E5%B8%A7%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[以太网的帧结构 字段 字段长度（字节） 目的 前导码(Preamble) 7 同步 帧开始符(SFD) 1 标明下一个字节为目的的MAC地址 目的的MAC地址 6 指明帧的接收者 源MAC地址 6 指明帧的发送者 长度（LENGTH） 2 帧的数据字段的长度（长度或类型） 类型（Type） 2 帧中数据的协议类型（长度或类型） 数据和填充（Data and Pad） 46~1500 高层的数据，通常为3层协议数据单元。对于TCP/IP是IP数据包 帧校验序列（FCS） 4 对接收网卡提供判断是否传输错误的一种方法，如果发现错误，丢弃此帧]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主方法定理]]></title>
    <url>%2F2016%2F09%2F19%2F%E7%AE%97%E6%B3%95%2F2016_09_19_%E4%B8%BB%E6%96%B9%E6%B3%95%E5%AE%9A%E7%90%86%2F</url>
    <content type="text"><![CDATA[常见的解递归的方法 代换法 猜测解的形式 使用数学归纳法找出使解真正有效的常熟 递归树法主方法定理设$a&gt;1$和 $b&gt;1$ 为常数,设 $f(n)$ 为一函数, $T(n)$ 由递归式 $$T(n) = aT(n/b) + f(n)$$ 对非负整数定义,其中$n/b$是指$\lfloor n/b \rfloor$或者是$\lceil n/b \rceil$.那么T(n)有如下的渐进界. 1) 若对于某常数$\varepsilon &gt; 0$,有$f(n) = O(n^{log_b^{a - \varepsilon}})$,则有$T(n) = \Theta (n^{log_b^{a }})$ 2) 若$f(n) = \Theta(n^{log_b^a})$,则有$T(n) = \Theta(n^{log_b^a}lg^n)$ 3) 若对某常数$\varepsilon &gt; 0$, 有$f(n) = \Omega(n^{log_b^{a + \varepsilon}})$,且对常数$c &lt; 1$与所有足够大的$n$,有$af(n/b) \le cf(n)$,则$T(n) = \Theta(f(n))$. 应用比较$f(n)$和$n^{log_a^b}$的大小. 在第一种情况中,可以看到应该是$n^{log_a^b}$比$f(n)$大.也就是说,$$ T(n)=\left{\begin{aligned}\Theta (n^{log_b^{a }}) &amp; &amp;{ n^{log_a^b} 0}\\Theta(n^{log_b^a}lg^n) &amp; &amp; {n^{log_a^b}=f(n), af(n/b)\le cf(n)}\\Theta(f(n)) &amp; &amp; {n^{log_a^b}}&gt;f(n)\end{aligned}\right.$$ 例子]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react学习(1)--基础]]></title>
    <url>%2F2016%2F08%2F26%2Ffront-end%2F2016_08_26_react%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[redux基本知识 redux基本知识 基本概念 action store reducer 基本概念 actionstorereducer]]></content>
      <categories>
        <category>Front-End</category>
      </categories>
      <tags>
        <tag>redux</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix-Network(3)-基本socket]]></title>
    <url>%2F2016%2F07%2F17%2Flinuxtcp%2F2016_07_17_unix-network(3)-%E5%9F%BA%E6%9C%ACsocket%2F</url>
    <content type="text"><![CDATA[基本socketsocket函数12345SYNOPSIS #include &lt;sys/socket.h&gt; int socket(int domain, int type, int protocol); family: 协议地址族 AF_xxx:表示地址族PF_xxx:表示协议族基本上都是采用的AF_xxx connect函数1234567SYNOPSIS #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int connect(int socket, const struct sockaddr *address, socklen_t address_len); 如果是TCP套接字，调用connect将发起三次握手，建立成功或出错返回，出错的情况如下： 若TCP客户端没有收到SYN分节的响应，则返回TIMEDOUT错误。举例来说，调用connect函数时，发送一个SYN包后若无响应则等待6s后再发一个，若无响应则再等待24s。若总共75s时仍未收到则出现本错误。 若对客户端的｀SYN｀的响应是RST,则表明该服务器主机在我们指定的端口没有进程在等待与之连接。这是一种硬错误，客户端一旦收到RST，则马上返回ECONNREFUSED错误。 产生RST的三个条件：一是目的地为某端口的SYN到达服务器，可是服务器端口并未开放；二是TCP想取消一个已有连接；三是TCP接收到一个根本不存在的连接上的分节。 若客户端发出的RST在中间的某个路由器引发了一个“destination unreachable”的ICMP错误，则认为这是一种软错误。客户机内核保存该消息，然后就像情况一一样继续发送，到规定时间（有的是75s）仍未响应，则把保存的消息作为EHOSTUNREACH或ENETUNREACH返回给进程。 端口扫描原理分析NMAP端口扫描TCP扫描的原理主要是三次握手。这种扫描也称为SYN扫描。Scanner向主机发起SYN请求。如果服务器回复SYN、ACK，这说明此端口开放。如果回复TCP、RST，表示端口未开放。如果没有回复，那么就可能没有这个服务器，或者数据包被防火墙丢弃。 UDP的扫描原理：由于UDP没有三次握手，所以UDP的扫描原理不一样。同样在Scanner发起一次UDP请求。如果服务器回复ICMP的端口不可达。则说明该服务器的此端口关闭。如果没有回应，这说明：一、服务器开放该端口。二、服务器主机不存在。三、被防火墙等设备丢弃。 ZMAP端口扫描 bind函数12345SYNOPSIS #include &lt;sys/socket.h&gt; int bind(int socket, const struct sockaddr *address, socklen_t address_len); 第二个参数是一个指向特定于协议的地址结构的指针，第三个为该地址结构的长度。返回的常见错误EADDRINUSE，地址已经被使用。 listen函数1234#include &lt;sys/socket.h&gt; int listen(int socket, int backlog); 为了理解bloglog参数，我们必须认识到内核为任何一个给定的监听的套结字维护两个队列： 1) 未完成连接队列，每个这样的SYN分节对应其中一项:已由某个客户端发出并到达服务器，而服务器正在等待完成相应的三次握手过程。这些套接字处于SYN_RCVD状态。 2）已完成连接队列，每个已完成TCP三路握手过程的客户端对应其中一项。这些套结字处于ESTABLISHED状态。 两队列之和不操过blacklog。 accept函数1234SYNOPSIS #include &lt;sys/socket.h&gt; int accept(int socket, struct sockaddr *restrict address, socklen_t *restrict address_len); 参数cliaddr和addrlen用来返回已连接的对端进程的协议地址，调用前，我们将由*addrlen所引用的整数值置为有cliaddr所指的套接字地址结构的长度，返回时，该整数值即为内核存放该套接字地址结构内的确切长度。所以address_len是一个值结果参数。 如果accept成功，那么其返回值是有内核自动生成的一个全新的描述符。 如果我们队客户协议地址不感兴趣，可以把后面两个参数均设置成空指针。 fork和exec函数并发服务器一个最简单的并发服务器123456789for(;;) &#123; connfd = accept(listen, ...); if ((pid = fork()) == 0) &#123; close(listenfd); doit(connfd); close(connfd); &#125; close(connfd);&#125; 对一个套接字调用colse方法，会导致内核发送一个FIN包，但是父进程调用了close(connfd),并没有发送FIN.因为每个文件或套接字都由一个引用计数，引用计数放在文件表项中维护。 getsockname和getpeername函数]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>network program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix-Network(2)-地址以及字符串操作函数]]></title>
    <url>%2F2016%2F07%2F17%2Flinuxtcp%2F2016_07_17_unix-network(2)-%E5%9C%B0%E5%9D%80%E4%BB%A5%E5%8F%8A%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[套接字地址结构IPV4套接字地址结构123456789101112struct in_addr &#123; in_addr_t s_addr;&#125;;struct sockaddr_in &#123; uint8_t sin_len; sa_family_t sin_family; in_port_t sin_port; struct in_addr sin_addr; char sin_zero[8];&#125;; 通用套接字1234```## 字节排序函数大端机和小端机 uint16_t htons(uint16_t host16bitvalue);uint32_t htonl(uint32_t host32bitvalue); uint16_t htonl(uint16_t net16bitvalue);uint32_t ntohl(uint32_t net32bitvalue);123456## 网络字节序和主机字节序## 字节操纵函数Berkeley的函数 #include void bzero(void dest, size_t nbytes);void bcopy(const void src, void dest, size_t nbytes);int bcmp(const void ptrl, const void *ptr2, size_t nbytes); 12ANSI C的函数 void memset(void dest, int c, size_t len);void memcpy(void dest, const void src, size_t nbytes);int memcmp(const void ptrl, const void *ptr2, size_t nbytes);12## 两组地址转换函数 int inet_aton(const char strptr, struct in_addr addrptr);in_addr_t inet_addr(const char strptr);char inet_ntoa(struct in_addr inaddr);``` readn, writen和readline函数字节流套接字（例如TCP套接字）上的read和write函数所表现的行为不同于通常的文件I/O。字节流套接字上调用read或write输入或输出的字节数可能比请求的数量少，然而这不是出错的状态。这个现象的原因在于内核中用于套接字的缓冲区可能已经达到了极限。]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix-Network(1)-基础]]></title>
    <url>%2F2016%2F07%2F17%2Flinuxtcp%2F2016_07_17_unix-network(1)-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[基本概念TCP的三次握手TCP选项TCP连接终止TCP的状态转换图TCP分组TIME_WAIT状态]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>network program</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim基本]]></title>
    <url>%2F2016%2F07%2F01%2Fvim%2F2016_07_01_vim%E5%9F%BA%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[VIM1 关于Vim vim是我最喜欢的编辑器，也是linux下第二强大的编辑器。虽然emacs是公认的世界第一，我认为使用emacs并没有使用vi进行编辑来得高效。如果是初学vi，运行一下vimtutor是个聪明的决定。2 启动Vim时的选项 * vim -c cmd file: 在打开文件前，先执行指定的命令； * vim -r file: 恢复上次异常退出的文件； * vim -R file: 以只读的方式打开文件； * vim -y num file: 将编辑窗口的大小设为num行； * vim + file: 从文件的末尾开始； * vim +num file: 从第num行开始； 3 光标的移动 * h: 左移一个字符； * l: 右移一个字符； * j: 下移一个字符； * k: 上移一个字符； * w: 前移一个单词，光标停在下一个单词开头； * e: 前移一个单词，光标停在下一个单词末尾； * b: 后移一个单词，光标停在上一个单词开头； * ge: 后移一个单词，光标停在上一个单词末尾； * fc: 把光标移到同一行的下一个c字符处 上面的操作都可以配合n使用，比如在正常模式(下面会讲到)下输入3h，则光标向左移动3个字符。 * 0或^:移动到行首。 * $: 移动到行尾。 * gg: 到文件头部。 * G: 到文件尾部。 * nG: 到文件第n行。 * :n&lt;cr&gt; 移动到第n行。 * :$&lt;cr&gt; 移动到最后一行。 * n|: 把光标移到递n列上。 * +或Enter:把光标移至下一行第一个非空白字符。 * -: 把光标移至上一行第一个非空白字符。 * H: 把光标移到屏幕最顶端一行。 * L: 把光标移到屏幕最底端一行。 * ctrl+f: 下翻一屏。 * ctrl+b: 上翻一屏。 * ctrl+d: 下翻半屏。 * ctrl+u: 上翻半屏。 4 Vim的几种模式 * 正常模式：可以使用快捷键命令，或按:输入命令行。 * 插入模式：可以输入文本，在正常模式下，按i、a、o等都可以进入插入模式。 * 可视模式：正常模式下按v可以进入可视模式，在可视模式下，移动光标可以选择文本。 * 块选择模式：正常模式下按ctrl+v进入。 * 替换模式：正常模式下，按R进入。 5 插入 * i: 在光标前插入； * I: 在当前行最前插入； * a: 在光标后插入； * A: 在当前行最后插入； * o: 在下面新建一行插入； * O: 在上面新建一行插入； * :r filename 在当前位置插入另一个文件的内容。 * :r !date 在光标处插入当前日期与时间。同理，:r!command可以将其它shell命令的输出插入当前文档。 6 改写 * c[n]w: 改写光标后1(n)个词。 * c[n]l: 改写光标后n个字母。 * c[n]h: 改写光标前n个字母。 * [n]cc: 修改当前[n]行。 * [n]s: 以输入的文本替代光标之后1(n)个字符，相当于c[n]l。 * [n]S: 删除指定数目的行，并以所输入文本代替之。 注意，类似cnw,dnw,ynw的形式同样可以写为ncw,ndw,nyw。7 替换 r: 替换光标处的字符，同样支持汉字。 R: 进入替换模式，按esc回到正常模式。 8 撤消与重做 * [n] u: 取消一(n)个改动。 * ctrl + r: 重做最后的改动。 * U: 取消当前行中所有的改动。 9 剪切和复制、粘贴 [n]x: 剪切光标右边n个字符，相当于d[n]l。 [n]X: 剪切光标左边n个字符，相当于d[n]h。 y: 复制在可视模式下选中的文本。 yy or Y: 复制整行文本。 y[n]w: 复制一(n)个词。 y[n]l: 复制光标右边1(n)个字符。 y[n]h: 复制光标左边1(n)个字符。 y$: 从光标当前位置复制到行尾。 y0: 从光标当前位置复制到行首。 :m,ny 复制m行到n行的内容。 y1G或ygg:复制光标以上的所有行。 yG: 复制光标以下的所有行。 d: 删除（剪切）在可视模式下选中的文本。 d$ or D: 删除（剪切）当前位置到行尾的内容。 d[n]w: 删除（剪切）1(n)个单词 d[n]l: 删除（剪切）光标右边1(n)个字符。 d[n]h: 删除（剪切）光标左边1(n)个字符。 d0: 删除（剪切）当前位置到行首的内容 [n] dd: 删除（剪切）1(n)行。 :m,nd 剪切m行到n行的内容。 d1G或dgg:剪切光标以上的所有行。 dG: 剪切光标以下的所有行。 p: 在光标之后粘贴。 P: 在光标之前粘贴。10 查找和替换 /something: 在后面的文本中查找something。 ?something: 在前面的文本中查找something。 n: 向后查找下一个。 N: 向前查找下一个。 :s/old/new: 用new替换当前行第一个old。 :s/old/new/g: 用new替换当前行所有的old。 :n1,n2s/old/new/g: 用new替换文件n1行到n2行所有的old。 :%s/old/new/g: 用new替换文件中所有的old。 :%s/^/xxx/g: 在每一行的行首插入xxx，^表示行首。 :%s/$/xxx/g: 在每一行的行尾插入xxx，^表示行尾。 所有替换命令末尾加上c，每个替换都将需要用户确认。如：%s/old/new/gc %: 找到对应的([{. 11 多行缩进缩出 * 正常模式下，按两下&gt;;光标所在行会缩进。 * 如果先按了n，再按两下&gt;;，光标以下的n行会缩进。 * 对应的，按两下&lt;;，光标所在行会缩出。 * 如果在编辑代码文件，可以用=进行调整。 * 在可视模式下，选择要调整的代码块，按=，代码会按书写规则缩排好。 * 或者n=，调整n行代码的缩排。 12 打开和关闭文档 * :e file –关闭当前编辑的文件，并开启新的文件。如果对当前文件的修改未保存，vi会警告。 * :e! file –放弃对当前文件的修改，编辑新的文件。 * :e+file – 开始新的文件，并从文件尾开始编辑。 * :e+n file – 开始新的文件，并从第n行开始编辑。 * :enew –编译一个未命名的新文档。 * :e – 重新加载当前文档。 * :e! – 重新加载当前文档，并丢弃已做的改动。 * :w – 保存修改。 * :n1,n2w filename – 选择性保存从某n1行到另n2行的内容。 * :wq – 保存并退出。 * :x – 保存并退出。 * :saveas newfilename – 另存为 13 多标签编辑 * :tabe filename – 在新的标签中打开一个文件。 * :tabn – 切换到下一个标签。 * :tabp – 切换到上一个标签。 14 分屏编辑14.1 水平分割 * :split(:sp) – 把当前窗水平分割成两个窗口。 * :split filename – 水平分割窗口，并在新窗口中显示另一个文件。 * :nsplit(:nsp) – 水平分割出一个n行高的窗口。 * :new – 水平分割出一个窗口，并编辑一个新文件。 * ctrl+w + –当前窗口增高一行。也可以用n增高n行。 * ctrl+w - –当前窗口减小一行。也可以用n减小n行。 * ctrl+w _ –当前窗口扩展到尽可能的大。 * n ctrl+w _ – 当前窗口的高度设定为n行。 14.2 垂直分割 * :vsplit(:vsp) – 把当前窗口分割成水平分布的两个窗口。 * :vnew – 垂直分割出一个新窗口。 * :vertical 水平分割的命令：相应的垂直分割。 14.3 关闭子窗口 * :qall – 关闭所有窗口，退出vim。 * :wall – 保存所有修改过的窗口。 * :only – 只保留当前窗口，关闭其它窗口。 * :close – 关闭当前窗口。(象 :q :x同样工作 ) 4.4 切换和移动窗口 ［如果支持鼠标，切换和调整子窗口的大小就简单了。］ * ctrl+w ctrl+w: 切换到下一个窗口。或者是ctrl+ww。 * ctrl+w h(l,j,k):切换到左（右，下，上）的窗口。 * ctrl+w t(b):切换到最上（下）面的窗口。&lt;BR&gt; * ctrl+w H(L,K,J): 将当前窗口移动到最左（右、上、下）面。 正因为vim强大的分屏功能，我们可以把vim打造成功能强大的IDE。15 一次编辑多个文件 我们可以一次打开多个文件，如 vi a.txt b.txt c.txt * 使用:next(:n)编辑下一个文件。 * 使用:previous编辑上一个文件。 * 使用:wnext，保存当前文件，并编辑下一个文件。 * 使用:wprevious，保存当前文件，并编辑上一个文件。 * 使用:args显示文件列表。 16 文件的编码 * :e ++enc=utf8 filename, 让vim用utf-8的编码打开这个文件。 * :w ++enc=gbk，不管当前文件什么编码，把它转存成gbk编码。 * :set fenc或:setfileencoding，查看当前文件的编码。 * 在vimrc中添加setfileencoding=utf-8,cp936,ucs-bom，vim会根据要打开的文件选择合适的编码。注意：编码之间不要留空格。cp936对应于gbk编码。ucs-bom对应于windows下的文件格式。 让vim正确处理文件格式和文件编码，有赖于~/.vimrc的正确配置。17 执行命令 * :! cmd 执行外部命令。 * :!! 执行上一次的外部命令。 * @: 重复上一次的冒号命令。 * :sh 调用shell，用exit返回vim。 * :r !cmd 将命令的返回结果插入文件当前位置。 * :m,nw !cmd 将文件的m行到n行之间的内容做为命令输入执行命令。 18 一些快捷键（收集中） * K: 打开光标所在词的manpage。 * *: 向下搜索光标所在词。 * #: 向上搜索光标所在词。 * ~: 反转光标所在字符的大小写。 * %: 移动到匹配的(),{}或[]上。]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unix基础编程(3)--文件和目录]]></title>
    <url>%2F2016%2F06%2F30%2Flinuxtcp%2F2016_06_30_unix%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B(3)--%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[文件和目录stat, fstat, fstatat 和 lstat1234567891011121314SYNOPSIS #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; int stat(const char *path, struct stat *buf); int fstat(int fd, struct stat *buf); int lstat(const char *path, struct stat *buf);SYNOPSIS #include &lt;fcntl.h&gt; /* Definition of AT_* constants */ #include &lt;sys/stat.h&gt; int fstatat(int dirfd, const char *pathname, struct stat *buf, int flags); 关于结构 stat 123456789101112131415struct stat &#123; dev_t st_dev; /* ID of device containing file */ ino_t st_ino; /* inode number */ mode_t st_mode; /* protection */ nlink_t st_nlink; /* number of hard links */ uid_t st_uid; /* user ID of owner */ gid_t st_gid; /* group ID of owner */ dev_t st_rdev; /* device ID (if special file) */ off_t st_size; /* total size, in bytes */ blksize_t st_blksize; /* blocksize for filesystem I/O */ blkcnt_t st_blocks; /* number of 512B blocks allocated */ time_t st_atime; /* time of last access */ time_t st_mtime; /* time of last modification */ time_t st_ctime; /* time of last status change */&#125;; 文件类型 1 普通文件 2 目录文件 3 块特殊文件(block special file).这种类型的文件提供对设备(如磁带)带缓冲的访问,每次访问以固定长度为单位进行. 4 字符特殊文件.这种类型的文件提供对设备不带缓冲的访问,每次访问长度是可变的. 5 FIFO 这种类型的文件用于进程间通信. 6 socket 用于进程间网络通信 7 符号链接 文件类型信息包含在stat结构的st_mode中 宏 文件类型 S_ISREG() 普通文件 S_ISDIR() 目录文件 S_ISCHR() 字符特殊文件 S_ISBLK() 块特殊文件 S_ISFIFO() 管道文件 S_ISLINK() 符号链接 S_ISSOCK() 套接字 POSIX.1允许实现将进程间通信(IPC)对象说明文件,使用stat结构中确定IPC对象类型,参数是指向stat结构的指针.| 宏 | 对象类型 || ————- |:————-:|| S_TYPEISMQ() | 消息队列 || S_TYPEISEM() | 信号量 || S_TYPEISSHM() | 共享存储对象 | 设置用户ID与组ID一个进程相关联的ID有6个或者更多 | S_TYPEISMQ() | 消息队列 || S_TYPEISEM() | 信号量 || S_TYPEISSHM() | 共享存储对象 | 设置用户ID和设置组ID实际用户ID实际组ID 有效用户ID有效组ID附属组ID 保存的设置用户ID保存的设置组ID 由exec函数保存 实际用户ID和实际组ID标识我们究竟是谁,这两个字段在登录时,取自哦令文件 有效用户,有效组ID以及附属组ID决定了我们的文件访问权限 保存的设置用户ID和保存的设置组ID在执行一个程序时,包含了一个有效用户ID和有效组ID的副本. 每一个文件有一个所有者和组所有者,所有者由stat结构中的st_uid指定,组所有者有st_git指定. 当执行一个程序文件时,进程的有效用户ID通常就是实际用户ID,有效组ID是实际组ID,但是可以在文件模式字std_mode中设置一个特殊标志,其含义是”当执行文件时,将进程的有效用户ID设置为文件所有者用户ID”,与此类似,文件模式字中可以设置的另一位,它将执行文件的有效组ID设置未文件的组所有者ID.可以使用S_ISUID和S_ISGID测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;int main(int argc, char **argv) &#123; int i; struct stat buf; char *ptr; for(i = 1; i &lt; argc; i++) &#123; printf(&quot;%s, &quot;, argv[i]); if (lstat(argv[i], &amp;buf) &lt; 0) &#123; printf(&quot;lstat error\n&quot;); continue; &#125; if (S_ISREG(buf.st_mode)) &#123; ptr = &quot;regular&quot;; &#125; else if (S_ISDIR(buf.st_mode)) &#123; ptr = &quot;dirctory&quot;; &#125; else if (S_ISCHR(buf.st_mode)) &#123; ptr = &quot;char special&quot;; &#125; else if(S_ISBLK(buf.st_mode)) &#123; ptr = &quot;kuai te shu&quot;; &#125; else if(S_ISFIFO(buf.st_mode)) &#123; ptr = &quot;FIFO&quot;; &#125; else if (S_ISLNK(buf.st_mode)) &#123; ptr = &quot;Link&quot;; &#125; else if(S_ISSOCK(buf.st_mode)) &#123; ptr = &quot;SOCKET&quot;; &#125; else &#123; ptr = &quot;UNKONWN&quot;; &#125; if (buf.st_mode &amp; S_ISUID) &#123; printf(&quot;suid\n&quot;); &#125; if (buf.st_mode &amp; S_ISGID) &#123; printf(&quot;sgid\n&quot;); &#125; printf(&quot;%s\n&quot;, ptr); &#125; exit(0);&#125; output:123./a.out /usr/bin/passwd/usr/bin/passwd, suidregular 文件访问权限st_mode也包含了文件的访问权限.S_IRUSR 用户读S_IWUSR 用户写S_IXUSR 用户执行 S_IRGRP 组读S_IWGRP 组写S_IXGRP 组执行 S_IROTH 其他读S_IWOTH 其他写S_IXOTH 其他执行 规则一,当我们用名字打开任一类型的文件时,对名字中包含的每一个目录,包括.和..都应该具有执行权限,目录的执行权限对应于搜索位.对目录而言,读权限和执行权限的区别:读权限允许我们读目录,获取该目录中所有文件列表名.当一个目录是我们要访问的文件路径名的一个组成部分时,对该目录的执行权限使我们可以通过该目录.12345&gt;ll /var/log -ddrwxrwxr-x 20 root syslog 4096 7月 6 09:05 /var/logsudo chmod 774 /var/log&gt;ll /var/log -ddrwxrwxr-- 20 root syslog 4096 7月 6 09:05 /var/log 结果:1234ll /var/log/dmesgls: cannot access /var/log/dmesg: Permission denied/var &gt;cd logcd: permission denied: log 可以ls,但是不能cd123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;#include &lt;errno.h&gt;extern int errno ;int main(int argc, char** argv) &#123; if (argc &lt; 2) &#123; printf(&quot;usage a.out &lt;dirname&gt;\n&quot;); exit(-1); &#125; DIR *dptr = NULL; struct dirent *entry; if ((dptr = opendir(argv[1])) == NULL) &#123; perror(&quot;Error:&quot;); &#125; else &#123; while (entry = readdir(dptr)) &#123; printf(&quot;%s\n&quot;, entry-&gt;d_name); &#125; closedir(dptr); &#125; return 0;&#125; 因为对其他人都取消了执行权限,所以其他人无法通过该目录了. 为了在目录中创建一个新文件,需要有写和执行的权限 为了删除一个现有文件文件,必须对包含该文件的目录有写权限和执行权限,对该文件本身则不需要读写权限 如果用7个exec函数中的任何一个执行文件,必须对该文件具有执行权限,并且该文件为普通文件. 新文件和目录的所有权新文件的用户ID设置为进程的有效用户ID,新文件的组ID:可以是进程的有效组ID;也可以是所在目录的组ID. 在ubuntu下是哪种情况?使用sudo,改变进程的有效用户,发现组ID是进程的有效组ID.在Mac里面则是所在目录的组ID 函数access和faccessat当open函数打开一个文件时,内核以进程的有效用户ID和有效组ID为基础进行访问权限测试.有时候,进程也希望按照实际用户ID和实际组ID来测试其访问能力.可以使用这两个函数. 1234SYNOPSIS #include &lt;unistd.h&gt; int access(const char *pathname, int mode); umask函数为一个进程设置文件模式创建屏蔽字,在进程创建一个新文件或者目录.参数是设置的umask值,返回的是之前的umask值.12345SYNOPSIS #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; mode_t umask(mode_t mask); 函数chmod, fchmod和fchmodat12345SYNOPSIS #include &lt;sys/stat.h&gt; int chmod(const char *path, mode_t mode); int fchmod(int fd, mode_t mode); 为了能够改变一个文件的权限位,进车个的有效用户ID必须等于文件的所有者ID. 粘着位(sticky bit)允许目录设置,如果对一个目录设置了粘着位,只有对该目录具有写权限的用户并且满足下列条件之一,才能删除或者重命名该目录下的文件. 拥有此文件 拥有此目录 是超级用户 /tmp和/var/tmp设置了粘着位,任何用户都可以创建目录,但其他人无法删除. chown,fchown,fchownat, lchown文件长度其他一些操作1234567891011121314151617181920212223#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main(int argv, char ** args) &#123; if(argv &gt; 1) &#123; const char * FILENAME = args[1]; int r_fd = open(FILENAME, O_RDWR); printf(&quot;%d\n&quot;, r_fd); off_t offeset = 2; int ft_res = ftruncate(r_fd, offeset); close(r_fd); &#125; else &#123; printf(&quot;%s &lt;filename&gt;\n&quot;, args[0]); &#125; return 0;&#125; fstat 获取文件的状态 stat(const char *path, struct stat *buf) fstat(int fd, struct stat *buf) lstat(const char *path, struct *buf) //链接文件返回：123456789101112131415struct stat &#123; dev_t st_dev; /* ID of device containing file */ ino_t st_ino; /* inode number */ mode_t st_mode; /* protection */ nlink_t st_nlink; /* number of hard links */ uid_t st_uid; /* user ID of owner */ gid_t st_gid; /* group ID of owner */ dev_t st_rdev; /* device ID (if special file) */ off_t st_size; /* total size, in bytes */ 文件的大小 blksize_t st_blksize; /* blocksize for file system I/O */ blkcnt_t st_blocks; /* number of 512B blocks allocated */ time_t st_atime; /* time of last access */ time_t st_mtime; /* time of last modification */ time_t st_ctime; /* time of last status change */ &#125;;]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unix编程基础(2)--文件IO]]></title>
    <url>%2F2016%2F06%2F23%2Flinuxtcp%2F2016_06_23_unix%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80(2)--%E6%96%87%E4%BB%B6io%2F</url>
    <content type="text"><![CDATA[Unix 文件IO文件描述符号对于内核而言,所有打开的文件通过文件描述符引用,是一个非负整数.在POSIX1中,在&lt;unistd.h&gt;中定义了STDIN_FILENO(0): 标准输入STDOUT_FILENO(1): 标准输出STDERR_FILENO(2): 标准错误输出 文件描述符号的范围是{0-OPEN_MAX-1} 函数open和openatman 2 openman 2 openat123456789101112SYNOPSIS #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; int open(const char *pathname, int flags); int open(const char *pathname, int flags, mode_t mode);SYNOPSIS #include &lt;fcntl.h&gt; int openat(int dirfd, const char *pathname, int flags); int openat(int dirfd, const char *pathname, int flags, mode_t mode); pathname: 打开或者是创建文件的名字 flags: 标识,使用下面的常量,多个可以使用 O_RDONLY 只读打开(0) O_WRONLY 只写打开(1) O_RDWR 读写打开 OS_EXEC 只执行打开 OS_SEARCH 搜索打开(不支持) 以上的这5个常量必须指定一个而且只能指定一个,下面的产量是可选的. O_APPEND O_CLOEXEC 把FD_CLOEXEC设置为文件描述符标志 O_CREAT 若文件不存在,则创建它,此时需要第三个参数(openat第四个)mode,指定权限位以及可以使用进程的umask修改 O_DIRECTORY 如果不是一个目录就会出错 O_EXCL 如果指定了O_CREAT并且文件存在则会出错 O_NOCTTY 如果path引用的是终端设备,则不将该设备分配作为该进程的控制终端. O_NOFOLLOW 如果path引用的是符号链接,则出错 O_NONBLOCK 如果path引用的是一FIFO,一个块特殊文件或者一个字符特殊文件,则此选项为文件的本次打开操作后和后续的I/O操作设置非阻塞方式. O_SYNC 使每次write等待物理I/O操作完成 O_TRUNC 如果此文件存在,而且为只写(或者读写)成功打开,则将其长度截断为0 O_TTY_INIT 如果打开一个还未打开的终端设备,设置非标准termios参数.下面两个参数是可选择的 O_DSYNC O_RSYNC creat创建一个文件,相当于open(path, O_WRONLY| O_CREAT | O_TRUNC, mode) close关闭一个文件,并且释放该进程加在该文件记录上的所有的锁 lseek每打开一个文件都有一个与其相关联的当前文件偏移量 12345SYNOPSIS#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence); read1234SYNOPSIS #include &lt;unistd.h&gt; ssize_t read(int fd, void *buf, size_t count); read函数需要搞清楚的几个问题在于返回值 返回读取到的字节数 若到了文件末尾,返回0 出错,返回-1 write返回值 返回写的字节数 出错,返回-1 I/O的效率在linux的ext4文件系统下,磁盘长度为4096字节read ahead预读技术 文件共享内核使用3种数据结构标示打开文件 1) 每个进程在进程表中都有一个记录项,记录项中包含了一张打开的文件描述符表,每个文件描述符占有一项,与每个文件描速符相关联的是: a) 文件状态标志 b) 指向文件表项的指针 2) 内核为所有打开文件维持一张文件表,每个文件表项包含 a) 文件状态标志(读,写) b) 当前文件偏移量 c) 指向文件v节点的指针 3) 每个打开的文件(或设备)都有一个v节点 当两个进程打开同一个文件 fcntl123456SYNOPSIS #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; int fcntl(int fd, int cmd, ... /* arg */ );该函数可以改变打开的文件的属性 fcntl函数有以下5个功能 (1) 复制一个已有的描述符(cmd=F_DUPFD 或 F_DUPFD_CLOEXEC) (2) 获取/设置文件描述符标志(cmd=F_GETFE 或 F_SETFD) (3) 获取/设置文件状态标志(cmd=F_GETFL 或 F_SETFL) (4) 获取/设置异步I/O所有权(cmd=F_GETOWN 或 F_SETOWN) (5) 获取/设置记录锁(cmd=F_GETLK,F_SETLK 或 F_SETLWK) 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char **argv) &#123; int val; if (argc != 2) &#123; printf(&quot;Usage: a.out &lt;descriptor&gt;\n&quot;); exit(-1); &#125; if ((val = fcntl(atoi(argv[1]), F_GETFL, 0)) &lt; 0 ) &#123; printf(&quot;fcntl error for fd %d\n&quot;, atoi(argv[1])); &#125; switch (val &amp; O_ACCMODE) &#123; case O_RDONLY: printf(&quot;read only\n&quot;); break; case O_WRONLY: printf(&quot;write only\n&quot;); break; case O_RDWR: printf(&quot;read write\n&quot;); break; default: printf(&quot;unkonw access mode&quot;); &#125; if (val &amp; O_APPEND) printf(&quot;, append\n&quot;); if (val &amp; O_NONBLOCK) printf(&quot;, nonblocking\n&quot;); if (val &amp; O_SYNC) &#123; printf(&quot;, synchronous writes\n&quot;); &#125;#if !defined(_POSIX_C_SOURCE) &amp;&amp; defined(O_FSYNC) &amp;&amp; (O_FSYNC != O_SYNC) if (val &amp; O_FSYNC) printf(&quot;, synchronous writes\n&quot;);#endif putchar(&apos;\n&apos;); return 0;&#125;]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq学习(3)--work_queue]]></title>
    <url>%2F2016%2F06%2F21%2Ftool%2F2016_06_21_rabbitmq%E5%AD%A6%E4%B9%A0(3)--work_queue%2F</url>
    <content type="text"><![CDATA[任务队列new_tasknew_task代码: 12345678910111213141516171819#!/usr/bin/env pythonimport pikaimport sysconnection = pika.BlockingConnection(pika.ConnectionParameters( host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;task_queue&apos;, durable=True)message = &apos; &apos;.join(sys.argv[1:]) or &quot;Hello World!&quot;channel.basic_publish(exchange=&apos;&apos;, routing_key=&apos;task_queue&apos;, body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent ))print(&quot; [x] Sent %r&quot; % message)connection.close() wokrer.py 123456789101112131415161718192021import pikaimport timeconnection = pika.BlockingConnection(pika.ConnectionParameters( host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;task_queue&apos;, durable=True)print(&apos; [*] Waiting for messages. To exit press CTRL+C&apos;)def callback(ch, method, properties, body): print(&quot; [x] Received %r&quot; % body) time.sleep(body.count(b&apos;.&apos;)) print(&quot; [x] Done&quot;) ch.basic_ack(delivery_tag = method.delivery_tag)channel.basic_qos(prefetch_count=1)channel.basic_consume(callback, queue=&apos;task_queue&apos;)channel.start_consuming()]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix编程基础(1)--系统概述]]></title>
    <url>%2F2016%2F06%2F21%2Flinuxtcp%2F2016_06_21_unix%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80(1)--%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Unix系统概述UNIX的系统架构一个比较直观的认识是,操作系统 kernel:运行于硬件之上系统调用(system call): 内核的接口 登录登录名shell 文件和目录文件系统文件名路径名 输入和输出文件描述符标准输入,标准输出和标准错误不带缓冲的IO 程序和进程程序进程和进程ID1234567891011121314151617181920212223242526#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main() &#123; printf(&quot;this pid is %ld\n&quot;, (long)getpid()); printf(&quot;this ppid is %ld\n&quot;, (long)getppid()); for(;;) &#123; &#125; return 0;&#125;/***pstree─gnome-terminal─┬─gnome-pty-helpe │ │ │ │ ├─zsh───sh───node───8*[&#123;node&#125;] │ │ │ │ ├─5*[zsh───ssh] │ │ │ │ ├─5*[zsh] │ │ │ │ ├─zsh───mongo───2*[&#123;mongo&#125;] │ │ │ │ ├─zsh───python─┬─python───5*[&#123;+ │ │ │ │ │ └─4*[&#123;python&#125;] │ │ │ │ ├─2*[zsh───python] │ │ │ │ ├─zsh───a.out**/ 进程控制线程和线程ID 123456SYNOPSIS #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; pid_t getpid(void); pid_t getppid(void); 错误处理用户标识(User-id)信号(Signals)时间(Time Value)系统调用和库函数]]></content>
      <categories>
        <category>Read</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Angular2基础学习]]></title>
    <url>%2F2016%2F06%2F15%2Ffront-end%2F2016_06_15_angular2%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Angular2基础学习Angular初识ES6工具链 systemjs – 通用模块加载器,支持AMD,CommonJS,ES6等各种格式的JS的模块加载 es6-module-loader – ES6模块加载器,systemjs会自动加载这个模块 traceur –ES6转码器,将ES6代码转换为当前浏览器支持的ES5代码.systemjs会自动加载 这个模块. Angular应用三步走1. 引入Angular2预定义类型1import &#123;Component, View, bootstrap&#125; from &quot;angualr2/anguar&quot;; 2. 实现一个Angualr2组件定义一个类,然后在这个类加注解123[@Component](/user/Component)(&#123;selector:&quot;ez-app&quot;&#125;)[@View](/user/View)(&#123;template:&quot;&lt;h1&gt;Hello,Angular2&lt;/h1&gt;&quot;&#125;)class EzApp&#123;&#125; @Component和@View都是给类EzApp附加的元信息， 被称为注解Annotation。 @Component最重要的作用是通过selector属性（值为CSS选择符），指定这个组件渲染到哪个DOM对象上。 @View最重要的作用是通过template属性，指定渲染的模板。 3. 渲染组件到DATE_FORMAT将组件渲染到DOM上，需要使用自举/bootstrap函数：1bootstrap(EzApp); 这个函数的作用就是通知Angular2框架将EzApp组件渲染到DOM树上。 注解/Annotation你一定好奇@Component和@View到底是怎么回事。看起来像其他语言（比如python） 的装饰器，是这样吗？ ES6规范里没有装饰器。这其实利用了traceur的一个实验特性：注解。给一个类 加注解，等同于设置这个类的annotations属性： 123//注解写法[@Component](/user/Component)(&#123;selector:&quot;ez-app&quot;&#125;)class EzApp&#123;...&#125; 等同于: 12class EzApp&#123;...&#125;EzApp.annotations = [new Component(&#123;selector:&quot;ez-app&quot;&#125;)]; 注解可以看做编译器（traceur）层面的语法糖，但和python的装饰器不同， 注解在编译时仅仅被放在annotation里，编译器并不进行解释展开 - 这个解释的工作是 Angular2完成的： 小结在Angular2中，bootstrap是围绕组件开始的，你定义一个组件，然后启动它。如果没有一个组件， 你甚至都没有办法使用Angular2！ 支持多种渲染引擎 以组件而非DOM为核心，意味着Angular2在内核隔离了对DOM的依赖 - DOM仅仅作为一种可选的渲染引擎存在：]]></content>
      <categories>
        <category>Front-End</category>
      </categories>
      <tags>
        <tag>Angular2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ci持续集成]]></title>
    <url>%2F2016%2F06%2F01%2Fdevops%2F2016_06_01_ci%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[CI持续集成项目直达这是一个500行实现的一个例子.该文章的中文翻译地址 什么是持续集成系统When developing software, we want to be able to verify that our new features or bug fixes are safe and work as expected. We do this by running tests against our code. Sometimes, developers will run tests locally to verify that their changes are safe, but developers may not have the time to test their code on every system their software runs in. Further, as more and more tests are added the amount of time required to run them, even only locally, becomes less viable. Because of this, continuous integration systems have been created. 当我们开发软件的时候,我们想要能够验证我们的新功能或者是修复的bug能够安全有效的想预期那样运行.我们通过重新测试我们的代码可以实现.有的时候,开发者会在本地来验证他们的代码的变更是否安全,但是开发者没有时间去测试他们的代码能否在所有可能的系统里面运行.进一步讲,需要的测试用例越多,就需要更多的事件去测试,即使是在本地,也只是很少的.因此,持续集成系统被创建了. Continuous Integration (CI) systems are dedicated systems used to test new code. Upon a commit to the code repository, it is the responsibility of the continuous integration system to verify that this commit will not break any tests. To do this, the system must be able to fetch the new changes, run the tests and report its results. Like any other system, it should also be failure resistant. This means if any part of the system fails, it should be able to recover and continue from that point. Continuous Integration (CI) systems主要集中于测试新的代码.当你提交代码到仓库的时候,持续集成系统应该验证这次提交是否应该测试.要做到中诶但,系统必须能够获取到新的变更,能够得到测试的结果和报告.像其他的系统一样,也是有容错机制的,这意味着你可以恢复到某个个点. This test system should also handle load well, so that we can get test results in a reasonable amount of time in the event that commits are being made faster than the tests can be run. We can achieve this by distributing and parallelizing the testing effort. This project will demonstrate a small, bare-bones distributed continuous integration system that is designed for extensibility. 这个测试系统也应该处理负载,这样我们可以得到测试结果在合理的时间内提交的事件是由速度比测试可以运行。我们可以实现通过分配和并行测试工作。这个项目将展示一个小,持续集成的分布式系统设计的可扩展性。 Project Limitations and NotesDue to the limitations of code length and unittest, I simplified test discovery. We will only run tests that are in a directory named tests within the repository. Continuous integration systems monitor a master repository which is usually hosted on a web server, and not local to the CI’s file systems. For the cases of our example, we will use a local repository instead of a remote repository. Continuous integration systems need not run on a fixed, regular schedule. You can also have them run every few commits, or per-commit. For our example case, the CI system will run periodically. This means if it is set up to check for changes in five-second periods, it will run tests against the most recent commit made after the five-second period. It won’t test every commit made within that period of time, only the most recent one. This CI system is designed to check periodically for changes in a repository. In real-world CI systems, you can also have the repository observer get notified by a hosted repository. Github, for example, provides “post-commit hooks” which send out notifications to a URL. Following this model, the repository observer would be called by the web server hosted at that URL to respond to that notification. Since this is complex to model locally, we’re using an observer model, where the repository observer will check for changes instead of being notified. CI systems also have a reporter aspect, where the test runner reports its results to a component that makes them available for people to see, perhaps on a webpage. For simplicity, this project gathers the test results and stores them as files in the file system local to the dispatcher process. Note that the architecture this CI system uses is just one possibility among many. This approach has been chosen to simplify our case study into three main components. 这个项目使用Git存储库的需要测试的代码。只有将使用标准源代码管理调用,所以如果你不熟悉Git但熟悉其他版本控制系统(VCS)像svn或Mercurial,你仍然可以跟随。由于代码长度和unittest的局限性,我简化测试发现。我们只会运行测试在一个目录中指定的测试库。持续集成系统监控主存储库通常驻留在一个web服务器,而不是当地的CI的文件系统。的情况下,我们的示例中,我们将使用一个本地存储库,而不是一个远程存储库。持续集成系统不需要在一个固定的运行,定期。你也可以让他们每隔几提交运行,或per-commit。在我们的示例中,CI系统会周期性地运行。这意味着如果是建立在五秒钟的时间检查更改,它将运行测试对最近提交后五秒的时间。它不会测试每一个提交了在这段时间内,只有最近的一个。这个CI系统旨在定期检查存储库的变化。在现实世界的CI系统中,也可以存储库观察者通过托管库得到通知。Github,例如,提供“post-commit钩子”URL发送通知。在这个模型中,存储库观察者将由web服务器托管调用该URL通知的回应。因为这是在本地复杂的模型,我们使用观察者模式,观察者会检查存储库的变化而不是通知。CI系统也有一个记者方面,测试运行器组件使得他们报道了他们的研究成果可供人们看到的,也许在一个网页。为简单起见,本项目收集测试结果并将它们存储在本地文件系统的文件调度过程。注意,架构这个CI系统使用只是一个在许多可能性。这种方法已被选为简化我们的案例研究分成三个主要组件。 IntroductionThe basic structure of a continuous integration system consists of three components: an observer, a test job dispatcher, and a test runner. The observer watches the repository. When it notices that a commit has been made, it notifies the job dispatcher. The job dispatcher then finds a test runner and gives it the commit number to test. There are many ways to architect a CI system. We could have the observer, dispatcher and runner be the same process on a single machine. This approach is very limited since there is no load handling, so if more changes are added to the repository than the CI system can handle, a large backlog will accrue. This approach is also not fault-tolerant at all; if the computer it is running on fails or there is a power outage, there are no fallback systems, so no tests will run. The ideal system would be one that can handle as many test jobs as requested, and will do its best to compensate when machines go down. To build a CI system that is fault-tolerant and load-bearing, in this project, each of these components is its own process. This will let each process be independent of the others, and let us run multiple instances of each process. This is useful when you have more than one test job that needs to be run at the same time. We can then spawn multiple test runners in parallel, allowing us to run as many jobs as needed, and prevent us from accumulating a backlog of queued tests. In this project, not only do these components run as separate processes, but they also communicate via sockets, which will let us run each process on a separate, networked machine. A unique host/port address is assigned to each component, and each process can communicate with the others by posting messages at the assigned addresses. This design will let us handle hardware failures on the fly by enabling a distributed architecture. We can have the observer run on one machine, the test job dispatcher on another, and the test runners on another, and they can all communicate with each other over a network. If any of these machines go down, we can schedule a new machine to go up on the network, so the system becomes fail-safe. This project does not include auto-recovery code, as that is dependent on your distributed system’s architecture, but in the real world, CI systems are run in a distributed environment like this so they can have failover redundancy (i.e., we can fall back to a standby machine if one of the machines a process was running on becomes defunct). For the purposes of this project, each of these processes will be locally and manually started distinct local ports. 持续集成系统的基本结构由三部分组成:一个观察者,一个测试作业调度器,一个测试运行器。观察者观测代码仓库库。当它发现一个commit时,它通知作业调度器。作业调度器然后发现一个测试运行器,使其提交测试。构建CI系统的方法有很多。我们可以有观察者,调度器和runner是相同的进程在同一台计算机上。这种方法是非常有限,由于没有对负载进行处理,如果大量的更改添加到库,CI系统将积累大量积压。这种方法也不是容错;如果计算机上运行发生故障或停电,没有后备系统,所以没有测试运行。理想的系统是一个能够处理请求尽可能多的测试工作,并且能够容灾。建立一个CI系统容错和承载,在这个项目中,每一个组件都是自己的过程。这将让每个过程是独立于他人,让我们每个流程的多个实例运行。这是有用的,当你有不止一个的测试工作,需要同时运行。我们可以产生多个并行测试,让我们尽可能多的工作需要,并阻止我们积累的排队测试。在这个项目中,不仅这些组件作为独立进程运行,但他们也通过套接字进行通信,这将让我们每个进程运行在一个单独的、网络化的机器。独特的主机/端口地址是分配给每个组件,和每个进程可以与别人交流,发布信息的分配地址。这个设计将让我们处理硬件故障动态通过启用一个分布式架构。我们可以有观察者在一台机器上运行,测试作业调度器,测试运行在另一个,他们都能通过网络相互通信。如果这些机器,我们可以安排一个新机器在网络上,所以这个系统就自动防故障装置。这个项目不包括自动恢复代码,因为这是依赖于分布式系统的架构,但在现实世界中,这样的CI系统是运行在分布式环境中,这样他们就可以有故障转移(即冗余。,我们可以回到一个备用计算机如果其中一个机器运行过程成为破产)。对于本项目,这些过程将在本地和手动开始不同的当地的端口。 Files in this ProjectThis project contains Python files for each of these components: the repository observer \newline (repo_observer.py), the test job dispatcher (dispatcher.py), and the test runner \newline (test_runner.py). Each of these three processes communicate with each other using sockets, and since the code used to transmit information is shared by all of them, there is a helpers.py file that contains it, so each process imports the communicate function from here instead of having it duplicated in the file. There are also bash script files used by these processes. These script files are used to execute bash and git commands in an easier way than constantly using Python’s operating system-level modules like os and subprocess. Lastly, there is a tests directory, which contains two example tests the CI system will run. One test will pass, and the other will fail. 这个项目包含为每个这些组件:Python文件存储库观察者(repo_observer.py),测试作业调度器(dispatcher.py),并测试运行器(test_runner.py)。这三个过程相互通信使用套接字,因为用于传输信息的代码是由所有人共享helpers.py文件,其中包含它,所以每个流程导入函数从这里交流而不是复制的文件。也有这些进程使用的bash脚本文件。这些脚本文件用于执行bash和git命令在一个更简单的方法比不断使用Python的操作系统级模块如操作系统和子流程。最后,有一个测试目录,它包含了两个示例测试CI系统将运行。一个测试能通过,另一个就会失败。 Inital SetupWhile this CI system is ready to work in a distributed system, let us start by running everything locally on one computer so we can get a grasp on how the CI system works without adding the risk of running into network-related issues. If you wish to run this in a distributed environment, you can run each component on its own machine. Continuous integration systems run tests by detecting changes in a code repository, so to start, we will need to set up the repository our CI system will monitor. Let’s call this test_repo: $ mkdir test_repo$ cd test_repo$ git initThis will be our master repository. This is where developers check in their code, so our CI should pull this repository and check for commits, then run tests. The thing that checks for new commits is the repository observer. The repository observer works by checking commits, so we need at least one commit in the master repository. Let’s commit our example tests so we have some tests to run. Copy the tests folder from this code base to test_repo and commit it:1234$ cp -r /this/directory/tests /path/to/test_repo/$ cd /path/to/test\_repo$ git add tests/$ git commit -m ”add tests” Now you have a commit in the master repository. The repo observer component will need its own clone of the code, so it can detect when a new commit is made. Let’s create a clone of our master repository, and call it test_repo_clone_obs:1$ git clone /path/to/test_repo test_repo_clone_obs The test runner will also need its own clone of the code, so it can checkout the repository at a given commit and run the tests. Let’s create another clone of our master repository, and call it test_repo_clone_runner:1$ git clone /path/to/test_repo test_repo_clone_runner 虽然这CI系统准备工作在分布式系统中,让我们从一台计算机上本地运行一切我们可以得到一个对CI系统如何工作在不增加的风险跑到网络相关问题。如果你想运行在分布式环境中,您可以运行自己的机器上的每个组件。持续集成系统通过检测运行测试代码库的变化,所以开始,我们将需要设置存储库CI系统将监测。]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logstalgia介绍]]></title>
    <url>%2F2016%2F05%2F04%2Ftool%2F2016_05_04_logstalgia%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[依赖于OpenGL 1234sudo apt-get install libglew-devsudo apt-get install libsdl-image1.2-devsudo apt-get install libboost-all-devsudo apt-get install libglm-dev 使用方法 1ssh user@exapmle.com tail -f /var/log/example.com.log | logstalgia]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python实现python解释器]]></title>
    <url>%2F2016%2F04%2F27%2Fpython%2F2016_04_27_python%E5%AE%9E%E7%8E%B0python%E8%A7%A3%E9%87%8A%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Python实现的Python解释器原文地址https://github.com/aosabook/500lines/blob/b5ee54148551b2e71991cf0a4858d86b671f6e52/interpreter/interpreter.markdown 项目直达这是一个500行实现的一个例子.该文章的中文翻译地址 介绍Byterun is a Python interpreter implemented in Python. Through my work on Byterun, I was surprised and delighted to discover that the fundamental structure of the Python interpreter fits easily into the 500-line size restriction. This chapter will walk through the structure of the interpreter and give you enough context to explore it further. The goal is not to explain everything there is to know about interpreters—like so many interesting areas of programming and computer science, you could devote years to developing a deep understanding of the topic. Byterun was written by Ned Batchelder and myself, building on the work of Paul Swartz. Its structure is similar to the primary implementation of Python, CPython, so understanding Byterun will help you understand interpreters in general and the CPython interpreter in particular. (If you don’t know which Python you’re using, it’s probably CPython.) Despite its short length, Byterun is capable of running most simple Python programs[^versions]. [^versions]: This chapter is based on bytecode produced by Python 3.5 or earlier, as there were some changes to the bytecode specification in Python 3.6. Python解释器解释器: 指的就是REPL(A read–eval–print loop ) 在解释器接手之前，Python会执行其他3个步骤：词法分析，语法解析和编译。这三步合起来把源代码转换成code object,它包含着解释器可以理解的指令。而解释器的工作就是解释code object中的指令。 A Python Python Interpretergcc就是C语言写的 Building an InterpreterPython解释器是一个虚拟机,模拟真实计算机的软件。我们这个虚拟机是栈机器，它用几个栈来完成操作（与之相对的是寄存器机器，它从特定的内存地址读写数据）。Python解释器是一个字节码解释器：它的输入是一些命令集合称作字节码。当你写Python代码时，词法分析器，语法解析器和编译器生成code object让解释器去操作。每个code object都包含一个要被执行的指令集合 — 它就是字节码 — 另外还有一些解释器需要的信息。字节码是Python代码的一个中间层表示：它以一种解释器可以理解的方式来表示源代码。这和汇编语言作为C语言和机器语言的中间表示很类似。 A Tiny Interpreter理解3个指令LOAD_VALUEADD_TOW_VALUEPRINT_ANSWER 假设你输入的是17+5 生成123456what_to_execute = &#123; &quot;instructions&quot;: [(&quot;LOAD_VALUE&quot;, 0), # the first number (&quot;LOAD_VALUE&quot;, 1), # the second number (&quot;ADD_TWO_VALUES&quot;, None), (&quot;PRINT_ANSWER&quot;, None)], &quot;numbers&quot;: [7, 5] &#125; Python解释器是一个栈机器，所以它必须通过操作栈来完成这个加法。(Figure 1.1)解释器先执行第一条指令，LOAD_VALUE，把第一个数压到栈中。接着它把第二个数也压到栈中。然后，第三条指令，ADD_TWO_VALUES,先把两个数从栈中弹出，加起来，再把结果压入栈中。最后一步，把结果弹出并输出。 12345678910111213141516class Interpreter: def __init__(self): self.stack = [] def LOAD_VALUE(self, number): self.stack.append(number) def PRINT_ANSWER(self): answer = self.stack.pop() print(answer) def ADD_TWO_VALUES(self): first_num = self.stack.pop() second_num = self.stack.pop() total = first_num + second_num self.stack.append(total) 上面3个方法完成了解释器的3个指令. 1234567891011def run_code(self, what_to_execute): instructions = what_to_execute[&quot;instructions&quot;] numbers = what_to_execute[&quot;numbers&quot;] for each_step in instructions: instruction, argument = each_step if instruction == &quot;LOAD_VALUE&quot;: number = numbers[argument] self.LOAD_VALUE(number) elif instruction == &quot;ADD_TWO_VALUES&quot;: self.ADD_TWO_VALUES() elif instruction == &quot;PRINT_ANSWER&quot;: 变量1234567891011what_to_execute = &#123; &quot;instructions&quot;: [(&quot;LOAD_VALUE&quot;, 0), (&quot;STORE_NAME&quot;, 0), (&quot;LOAD_VALUE&quot;, 1), (&quot;STORE_NAME&quot;, 1), (&quot;LOAD_NAME&quot;, 0), (&quot;LOAD_NAME&quot;, 1), (&quot;ADD_TWO_VALUES&quot;, None), (&quot;PRINT_ANSWER&quot;, None)], &quot;numbers&quot;: [1, 2], &quot;names&quot;: [&quot;a&quot;, &quot;b&quot;] &#125; 变量 1234567891011121314151617181920212223242526272829303132333435363738394041class Interpreter: def __init__(self): self.stack = [] self.environment = &#123;&#125; def STORE_NAME(self, name): val = self.stack.pop() self.environment[name] = val def LOAD_NAME(self, name): val = self.environment[name] self.stack.append(val) def parse_argument(self, instruction, argument, what_to_execute): &quot;&quot;&quot; Understand what the argument to each instruction means.&quot;&quot;&quot; numbers = [&quot;LOAD_VALUE&quot;] names = [&quot;LOAD_NAME&quot;, &quot;STORE_NAME&quot;] if instruction in numbers: argument = what_to_execute[&quot;numbers&quot;][argument] elif instruction in names: argument = what_to_execute[&quot;names&quot;][argument] return argument def run_code(self, what_to_execute): instructions = what_to_execute[&quot;instructions&quot;] for each_step in instructions: instruction, argument = each_step argument = self.parse_argument(instruction, argument, what_to_execute) if instruction == &quot;LOAD_VALUE&quot;: self.LOAD_VALUE(argument) elif instruction == &quot;ADD_TWO_VALUES&quot;: self.ADD_TWO_VALUES() elif instruction == &quot;PRINT_ANSWER&quot;: self.PRINT_ANSWER() elif instruction == &quot;STORE_NAME&quot;: self.STORE_NAME(argument) elif instruction == &quot;LOAD_NAME&quot;: self.LOAD_NAME(argument) 可以看到run_code的方法已经很冗长了.使用python的动态方法查找 12345678910def execute(self, what_to_execute): instructions = what_to_execute[&quot;instructions&quot;] for each_step in instructions: instruction, argument = each_step argument = self.parse_argument(instruction, argument, what_to_execute) bytecode_method = getattr(self, instruction) if argument is None: bytecode_method() else: bytecode_method(argument) Real Python Bytecodepython字节码 1234567&gt;&gt;&gt; def cond():... x = 3... if x &lt; 5:... return &apos;yes&apos;... else:... return &apos;no&apos;... 使用cond.__code__可以看到其字节码,但是看上去难以理解 123456&gt;&gt;&gt; cond.__code__.co_code # the bytecode as raw bytesb&apos;d\x01\x00&#125;\x00\x00|\x00\x00d\x02\x00k\x00\x00r\x16\x00d\x03\x00Sd\x04\x00Sd\x00 \x00S&apos;&gt;&gt;&gt; list(cond.__code__.co_code) # the bytecode as numbers[100, 1, 0, 125, 0, 0, 124, 0, 0, 100, 2, 0, 107, 0, 0, 114, 22, 0, 100, 3, 0, 83, 100, 4, 0, 83, 100, 0, 0, 83] 使用标准库中的dis module来解决这个问题. 12345678910111213141516&gt;&gt;&gt; dis.dis(cond) 2 0 LOAD_CONST 1 (3) 3 STORE_FAST 0 (x) 3 6 LOAD_FAST 0 (x) 9 LOAD_CONST 2 (5) 12 COMPARE_OP 0 (&lt;) 15 POP_JUMP_IF_FALSE 22 4 18 LOAD_CONST 3 (&apos;yes&apos;) 21 RETURN_VALUE 6 &gt;&gt; 22 LOAD_CONST 4 (&apos;no&apos;) 25 RETURN_VALUE 26 LOAD_CONST 0 (None) 29 RETURN_VALUE 第一列的数字标示对应的源码行数第二列数字是字节码的索引第三列是指令本省对应的名字第四列标示之列那个 参数第五列标示关于参数的提示 Conditrionals and Loops12345678910111213141516171819202122232425&gt;&gt;&gt; def loop():... x = 1... while x &lt; 5:... x = x + 1... return x...&gt;&gt;&gt; dis.dis(loop) 2 0 LOAD_CONST 1 (1) 3 STORE_FAST 0 (x) 3 6 SETUP_LOOP 26 (to 35) &gt;&gt; 9 LOAD_FAST 0 (x) 12 LOAD_CONST 2 (5) 15 COMPARE_OP 0 (&lt;) 18 POP_JUMP_IF_FALSE 34 4 21 LOAD_FAST 0 (x) 24 LOAD_CONST 1 (1) 27 BINARY_ADD 28 STORE_FAST 0 (x) 31 JUMP_ABSOLUTE 9 &gt;&gt; 34 POP_BLOCK 5 &gt;&gt; 35 LOAD_FAST 0 (x) 38 RETURN_VALUE Explore Bytecode我鼓励你用dis.dis来试试你自己写的函数。一些有趣的问题值得探索： 对解释器而言for循环和while循环有什么不同？ 能不能写出两个不同函数，却能产生相同的字节码? elif是怎么工作的？列表推导呢？ Frames一个frame是一些信息的集合和代码的执行上下文。frames在Python代码执行时动态的创建和销毁。每个frame对应函数的一次调用。— 所以每个frame只有一个code object与之关联，而一个code object可以很多frame。比如你有一个函数递归的调用自己10次，这时有11个frame。总的来说，Python程序的每个作用域有一个frame，比如，每个module，每个函数调用，每个类定义。 ex: 12345678910&gt;&gt;&gt; def bar(y):... z = y + 3 # &lt;--- (3) ... and the interpreter is here.... return z...&gt;&gt;&gt; def foo():... a = 1... b = 2... return a + bar(b) # &lt;--- (2) ... which is returning a call to bar ......&gt;&gt;&gt; foo() # &lt;--- (1) We&apos;re in the middle of a call to foo ... 在，解释器在foo函数的调用中。调用栈中有3个fram：一个对应于module层，一个对应函数foo,别一个对应函数bar。(Figure 1.2)一旦bar返回，与它对应的frame就会从调用栈中弹出并丢弃。 我惊讶的发现Python真的很少依赖于每个frame有一个数据栈这个特性。在Python中几乎所有的操作都会清空数据栈，所以所有的frame公用一个数据栈是没问题的。在上面的例子中，当bar执行完后，它的数据栈为空。即使foo公用这一个栈，它的值也不会受影响。然而，对应生成器，一个关键的特点是它能暂停一个frame的执行，返回到其他的frame，一段时间后它能返回到原来的frame，并以它离开时的同样的状态继续执行。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OAuth授权认证]]></title>
    <url>%2F2016%2F04%2F27%2FHTTP%2F2016_04_27_oauth%E6%8E%88%E6%9D%83%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql出现Lock-Wait-Timeout]]></title>
    <url>%2F2016%2F04%2F21%2FMISC%2F2016_04_21_mysql%E5%87%BA%E7%8E%B0lock-wait-timeout%2F</url>
    <content type="text"><![CDATA[mysql出现Lock Wait Timeout使用的RDS,出现了Lock Wait Timeout的问题解决方法 以ROOT用户登录数据库后执行SHOW FULL PROCESSLIST,然后KILL &lt;id&gt;]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的时间查询操作]]></title>
    <url>%2F2016%2F04%2F20%2FSQL%2F2016_04_20_mysql%E7%9A%84%E6%97%B6%E9%97%B4%E6%9F%A5%E8%AF%A2%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[MySQL关于时间的查询 1 、 查看当天日期 1select current_date(); 2、 查看当天时间 1select current_time(); 3、查看当天时间日期 1select current_timestamp(); 4、查询当天记录 1select * from 表名 where to_days(时间字段名) = to_days(now()); 5、查询昨天记录 1SELECT * FROM 表名 WHERE TO_DAYS( NOW( ) ) – TO_DAYS( 时间字段名) &lt;= 1 6、查询7天的记录 1SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 7 DAY) &lt;= date(时间字段名) 7、查询近30天的记录 1SELECT * FROM 表名 where DATE_SUB(CURDATE(), INTERVAL 30 DAY) &lt;= date(时间字段名) 8、查询本月的记录 1SELECT * FROM 表名 WHERE DATE_FORMAT( 时间字段名, ‘%Y%m’ ) = DATE_FORMAT( CURDATE( ) , ‘%Y%m’ ) 9、查询上一月的记录 1SELECT * FROM 表名 WHERE PERIOD_DIFF( date_format( now( ) , ‘%Y%m’ ) , date_format( 时间字段名, ‘%Y%m’ ) ) =1 10、查询本季度数据 1select * from 表名 where QUARTER(create_date)=QUARTER(now()); 11、查询上季度数据 1select * from 表名 where QUARTER(create_date)=QUARTER(DATE_SUB(now(),interval 1 QUARTER)); 12、查询本年数据 1select * from 表名 where YEAR(create_date)=YEAR(NOW()); 13、查询上年数据 1select * from 表名 where year(create_date)=year(date_sub(now(),interval 1 year)); 14、查询当前这周的数据 1SELECT * FROM 表名 WHERE YEARWEEK(date_format(submittime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now()); 15、查询上周的数据 1SELECT * FROM 表名 WHERE YEARWEEK(date_format(submittime,&apos;%Y-%m-%d&apos;)) = YEARWEEK(now())-1; 16、查询当前月份的数据 1select * from 表名 where date_format(submittime,&apos;%Y-%m&apos;)=date_format(now(),&apos;%Y-%m&apos;) 17、查询距离当前现在6个月的数据 1select name,submittime from enterprise where submittime between date_sub(now(),interval 6 month) and now();]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python打包和发布]]></title>
    <url>%2F2016%2F04%2F19%2Fpython%2F2016_04_19_python%E6%89%93%E5%8C%85%E5%92%8C%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[setuptools工具编写setupt.py文件12from setuptools import setupsetup(name=&quot;pyIP&quot;) 12345678910111213141516171819202122232425262728293031323334python setup.py --help-commandsStandard commands: build build everything needed to install build_py &quot;build&quot; pure Python modules (copy to build directory) build_ext build C/C++ extensions (compile/link to build directory) build_clib build C/C++ libraries used by Python extensions build_scripts &quot;build&quot; scripts (copy and fixup #! line) clean clean up temporary files from &apos;build&apos; command install install everything from build directory install_lib install all Python modules (extensions and pure Python) install_headers install C/C++ header files install_scripts install scripts (Python or otherwise) install_data install data files sdist create a source distribution (tarball, zip file, etc.) register register the distribution with the Python package index bdist create a built (binary) distribution bdist_dumb create a &quot;dumb&quot; built distribution bdist_rpm create an RPM distribution bdist_wininst create an executable installer for MS Windows upload upload binary package to PyPI check perform some checks on the packageExtra commands: develop install package in &apos;development mode&apos; saveopts save supplied options to setup.cfg or other config file egg_info create a distribution&apos;s .egg-info directory upload_docs Upload documentation to PyPI alias define a shortcut to invoke one or more commands easy_install Find/get/install Python packages rotate delete older distributions, keeping N newest files bdist_egg create an &quot;egg&quot; distribution install_egg_info Install an .egg-info directory for the package test run unit tests after in-place build setopt set an option in setup.cfg or another config file sdist–创建一个发行树1python setup.py sdist 如果需要执行脚本1scripts=[&apos;bin/sshtool.py&apos;] register和upload命令pypi服务器,位于http://pypi.python.org/pypi.这是distutils包所使用的默认服务器. 123python setup.py registerpython setup.py sdist uploadpython setup.py sdist upload -r pypi-server //可以选择服务器 会在主目录下存在一个.pypirc的文件保存帐号和密码.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python和MongoDB--Using MongoEngine]]></title>
    <url>%2F2016%2F04%2F14%2Fpython%2F2016_04_14_python%E5%92%8Cmongodb--using-mongoengine%2F</url>
    <content type="text"><![CDATA[Python操作MongoDB–使用MongoEnginepython操作mongo的模块用很多,如果你习惯与ORM,那么推荐使用MongoEngine. RefernceField可以很方便的构建一对多或多对多的关系 oreder_byupdate]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>MongoDB</tag>
        <tag>MongoEngine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Window折腾Python]]></title>
    <url>%2F2016%2F04%2F09%2Fpython%2F2016_04_09_window%E4%B8%8B%E6%8A%98%E8%85%BEpython%2F</url>
    <content type="text"><![CDATA[Windows下折腾pythonUnable to find vcvarsall.bat命令行下执行1SET VS90COMNTOOLS=%VS100COMNTOOLS% 如果你安装的是 2012 版1SET VS90COMNTOOLS=%VS110COMNTOOLS% 如果你安装的是 2013版1SET VS90COMNTOOLS=%VS120COMNTOOLS% 或者更暴力，直接配置系统环境变量 VS90COMNTOOLS指向 %VS你的版本COMNTOOLS% 你还可以更暴力，在..python安装路径...\Lib\distutils目录下有个msvc9compiler.py找到243行 toolskey = &quot;VS%0.f0COMNTOOLS&quot; % version 直接改为 toolskey = &quot;VS你的版本COMNTOOLS&quot;(这个就是为什么要配 ”VS90COMNTOOLS“ 的原因，因为人家文件名都告诉你了是 Microsoft vc 9的compiler, 代码都写死了要vc9的comntools，就要找这个玩意儿，找不到不干活) 这么做的理由是Python2.7 扩展包是可以用08版或者更高的VS编译的，其setup.py(安装脚本)都是去windows系统寻找08版的VS,所以设置VS90的path 如果Python版本小于2.7，强烈建议使用 VS08版，用2010或者更高可能部分扩展不好使。给个例子： 在安装一些Python模块时，大部分是cpython写的模块时会发生如下错误 error: Unable to find vcvarsall.bat先前的一篇文章：在Windows上安装Scrapy时也讲到了这个问题。当时讲到的方案是，安装VS 2008进行解决，但是Vs 2008又太大，不想装，所以这次想到了另外的方案，同样是上次说的，当时上次很不完整。解决方案一：安装Vs2008（实测）完全的无脑流，安装完问题直接解决。解决方案二：安装Vs2010（未测试）上次在电脑上装个Vs2010并不能像 vs2008那样直接解决问题，从网上找到如下解决方案，不知是否可行。打开&lt;python安装目录&gt;\Lib\distutils\msvc9compiler.py找到 toolskey = &quot;VS%0.f0COMNTOOLS&quot; % version，直接修改为 toolskey = &quot;VS100COMNTOOLS&quot;解决方案三：安装MinGW（实测） 1、下载安装MinGW，下载地址为：MinGW2、在MinGW的安装目录下找到bin文件夹，找到mingw32-make.exe，复制一份更名为make.exe3、把MinGW的路径添加到环境变量path中，比如我把MinGW安装到D:\MinGW\中，就把D:\MinGW\bin添加到path中；4、在&lt;python安装目录&gt;\distutils增加文件distutils.cfg，在文件里输入12[build]compiler=mingw32 保存； 5、执行原先的模块安装，发现还是报错，报错内容为1：error: command ‘gcc’ failed: No such file or directory 解决方案是将D:\MinGW\lib再添加到PATH中。 6、如果安装过程中出现 error: Could not find ‘openssl.exe’ 则直接到http://pypi.python.org/pypi/pyOpenSSL/0.13 下载安装即可。7、再次执行时安装模块时，发现如下错误：12345D:\MinGW\bin\gcc.exe -mno-cygwin -mdll -O -Wall “-ID:\Program Files\Python27\include” “-ID:\Program Files\Python27\include” “-ID:\Program Files\Python27\PC” -c../libdasm.c -o build\temp.win32-2.7\Release\..\libdasm.occ1.exe: error:unrecognized command line option ‘-mno-cygwin’error: command ‘gcc’ failed with exit status 1 原因是gcc 4.6.x 以后不再接受-mno-cygwin为了解决这个问题需要修改&lt;python安装目录&gt;\distutils\cygwinccompiler.py文件。找到： 1234567self.set_executables(compiler=&amp;#039;gcc -mno-cygwin -O -Wall&amp;#039;, compiler_so=&amp;#039;gcc -mno-cygwin -mdll -O -Wall&amp;#039;, compiler_cxx=&amp;#039;g++ -mno-cygwin -O -Wall&amp;#039;, linker_exe=&amp;#039;gcc&amp;#039;, linker_so=&amp;#039;%s -mno-cygwin %s %s&amp;#039; % (self.linker_dll, shared_option, entry_point)) 修改为： 1234567self.set_executables(compiler=&amp;#039;gcc -O -Wall&amp;#039;, compiler_so=&amp;#039;gcc -mdll -O -Wall&amp;#039;, compiler_cxx=&amp;#039;g++ -mno-cygwin -O -Wall&amp;#039;, linker_exe=&amp;#039;gcc&amp;#039;, linker_so=&amp;#039;%s -mno-cygwin %s %s&amp;#039; % (self.linker_dll, shared_option, entry_point)) an No module named Crypto.PublicKey明明安装了1pip install pycrypto 解决方法：We should rename crypto directory under “Lib/site-packages” to Crypto因为windows是不区分大小写的，但是py加载模块区分。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RAML初识]]></title>
    <url>%2F2016%2F04%2F05%2FHTTP%2F2016_04_05_raml%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[RAMLraml()在线的API designer tool ENTER THE ROOT确定根的url12345#%RAML 1.0 --- title: e-BookMobile API baseUri: http://api.e-bookmobile.com/&#123;version&#125; version: v1 ENTER RESOURCES确定资源，资源一般都是一个名词123/users: /authors: /books: ENTER METHODS确定方法1234/books: get: post: put: ENTER URI PARAMETERS确定URI的参数123456789101112/books: get: put: post: /&#123;bookTitle&#125;: get: put: delete: /author: get: /publisher: get: 确定查询的参数1234567891011/books: /&#123;bookTitle&#125; get: queryParameters: author: publicationYear: rating: isbn: put: queryParameters: access_token: 12345678910111213141516171819202122232425262728293031323334/books: /&#123;bookTitle&#125; get: queryParameters: author: displayName: Author type: string description: An author&apos;s full name example: Mary Roach required: false publicationYear: displayName: Pub Year type: number description: The year released for the first time in the US example: 1984 required: false rating: displayName: Rating type: number description: Average rating (1-5) submitted by users example: 3.14 required: false isbn: displayName: ISBN type: string minLength: 10 example: 0321736079? put: queryParameters: access_token: displayName: Access Token type: string description: Token giving you permission to make call required: true ENTER RESPONSES12345678910111213141516171819202122/books: /&#123;bookTitle&#125;: get: description: Retrieve a specific book title responses: 200: body: application/json: example: | &#123; &quot;data&quot;: &#123; &quot;id&quot;: &quot;SbBGk&quot;, &quot;title&quot;: &quot;Stiff: The Curious Lives of Human Cadavers&quot;, &quot;description&quot;: null, &quot;datetime&quot;: 1341533193, &quot;genre&quot;: &quot;science&quot;, &quot;author&quot;: &quot;Mary Roach&quot;, &quot;link&quot;: &quot;http://e-bookmobile.com/books/Stiff&quot;, &#125;, &quot;success&quot;: true, &quot;status&quot;: 200 &#125;]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python面向对象--描述符和属性]]></title>
    <url>%2F2016%2F03%2F30%2Fpython%2F2016_03_30_python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1--%E6%8F%8F%E8%BF%B0%E7%AC%A6%E5%92%8C%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[python面向对象–描述符和属性python中的私有属性python中没有访问限制的描速符.通过__符号来实现 Ex: 12class MyClass(object): __secret_value = 1 1234567In [3]: m.__secret_value---------------------------------------------------------------------------AttributeError Traceback (most recent call last)&lt;ipython-input-3-3a26128381d5&gt; in &lt;module&gt;()----&gt; 1 m.__secret_valueAttributeError: &apos;MyClass&apos; object has no attribute &apos;__secret_value&apos; 查看属性1234In [4]: dir(m)Out[4]:[&apos;_MyClass__secret_value&apos;, &apos;__class__&apos;, 其实也并不是真正意义上的私有属性. 描述符描述符用来自定义在引用一个对象上的特性时所应该完成的事情.基于如下三个特殊的方法 __set__ 在任何属性被设置时调用,setter; __get__ 在任何属性被读取的时候被调用,getter; __delete__这些方法都在 __dict__之前被调用. 其实就是通过一个类,对另外一个类的某个属性进行控制 1234567891011121314class UpperString(object): def __init__(self): self._val = &quot;&quot; def __get__(self, instance, klass): return self._val def __set__(self, instance, value): self._val = value.upper()class MyClass(object): attribute = UpperString()mc = MyClass()mc.attribute = &quot;my value&quot;print mc.attribute 自省描述符12345678910111213141516171819202122232425262728293031323334353637class API(object): def _print_values(self, obj): def _print_value(key): if key.startswith('_'): return '' value = getattr(obj, key) if not hasattr(value, 'im_func'): doc = type(value).__name__ else: if value.__doc__ is None: doc = 'no docstring' else: doc = value.__doc__ return " %s : %s" % (key, value) res = [_print_value(el) for el in dir(obj)] return '\n'.join([el for el in res if el != ""]) def __get__(self, instance, klass): if instance is not None: return self._print_values(instance) else: return self._print_values(klass)class MyClass(object): __doc__ = API() def __init__(self): self.a = 2 def meth(self): ''' my method ''' return 1print MyClass.__doc__instance = MyClass()print "========"print instance.__doc__ output: 1234meth : &lt;unbound method MyClass.meth&gt;========a : 2meth : &lt;bound method MyClass.meth of &lt;__main__.MyClass object at 0x7fe3295bcad0&gt;&gt; 元描述符属性属性提供了一个内建的描述符类型,属性采用fget和3个可选的参数–fset, fdel和doc 槽这个概念很少遇到]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>OOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[with和contextlib]]></title>
    <url>%2F2016%2F03%2F28%2Fpython%2F2016_03_28_with%E5%92%8Ccontextlib%2F</url>
    <content type="text"><![CDATA[with和contgextlib应用场景即使运行失败也要退出,比如: 关闭一个文件 释放一个锁 创建一个临时的代码补丁 在特殊环境中运行受保护的代码 with语句和上下文协议最常用的是打开和关闭一个文件 1234from __future__ import with_statement# 在2.5 以及2.5之前,需要这样引入with open(&apos;/etc/hosts&apos;) as fd: for line in fd 实现with的协议如下: 12345678910111213class Context(object): def __enter__(self): print(&quot;entering the zone&quot;) def __exit__(self, exception_type, exception_value, exception_traceback): print(&apos;leaving the zone&apos;) if exception_type is None: print(&apos;no error&apos;) else: print(&quot;with an error (%s)&quot; % exception_value)with Context(): print(&quot;i an the zone&quot;) output12345entering the zonei an the zoneleaving the zoneno error[Finished in 0.1s] 在py中,一个类实现两个方法 __enter__和__exit__,就实现了with协议,thread和threading模块的一些类也实现了这些方法thread.LockTypethreading.Lockthreading.RLockthreading.Conditionthreading.Semaphorethreading.BoundedSemaphore contextlib模块给with提供了一个辅助类,包含了一yield分开的__enter__和__exit__,所以上面的离职可以写成12345678910111213141516from contextlib import contextmanager# from __future__ import with_statement@contextmanagerdef context(): print(&quot;entering the zone&quot;) try: yield except Exception, e: print(&quot;with an error (%s) % e&quot;) raise e else: print(&quot;with no error&quot;)with context(): print(&quot;starting&quot;) 上下文实例]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins初识]]></title>
    <url>%2F2016%2F03%2F23%2Fdevops%2F2016_03_23_jenkins%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Jenkins初识安装(ubuntu14.04)安装123456wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key | sudo apt-key addsudo sh -c 'echo deb http://pkg.jenkins-ci.org/debian binary/ &gt; /etc/apt/sources.list.d/jenkins.list' sudo apt-get update -y sudo apt-get install jenkins -y 安装目录：/var/lib/jenkins日志目录：/var/log/jenkins/jenkins.log 3.启动/停止12sudo /etc/init.d/jenkins start sudo /etc/init.d/jenkins stop]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq学习(2)--生产者和消费者]]></title>
    <url>%2F2016%2F03%2F13%2Ftool%2F2016_03_13_rabbitmq%E5%AD%A6%E4%B9%A0(2)--%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[rabbitmq生产者和消费者send.py 1234567891011121314#!/usr/bin/env pythonimport pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;hello&apos;)channel.basic_publish(exchange=&apos;&apos;, routing_key=&apos;hello&apos;, body=&apos;Hello World!&apos;)print(&quot; [x] Sent &apos;Hello World!&apos;&quot;)connection.close() recive.py 123456789101112131415161718#!/usr/bin/env pythonimport pikaconnection = pika.BlockingConnection(pika.ConnectionParameters( host=&apos;localhost&apos;))channel = connection.channel()channel.queue_declare(queue=&apos;hello&apos;)def callback(ch, method, properties, body): print(&quot; [x] Received %r&quot; % body)channel.basic_consume(callback, queue=&apos;hello&apos;, no_ack=True)print(&apos; [*] Waiting for messages. To exit press CTRL+C&apos;)channel.start_consuming()]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列]]></title>
    <url>%2F2016%2F03%2F09%2Fpython%2F2016_03_09_celery%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[Celery分布式任务队列Choosing a BrokerRabbitMQRedisDatabbase(SQLAlchemy/Django Database)Create app1234567from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://guest@localhost//&apos;)@app.taskdef add(x, y): return x + y Create Celery Server1celery -A tasks worker --loglevel=info Call APP12&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; add.delay(4, 4) Results如果你想保存结果 1CELERY_RESULT_BACKEND = &apos;redis://localhost:6379/0&apos; Task通过使用装饰器task(),就可以创建一个task了. names一种好的实践模式是使用模块名字当作人物名123&gt;&gt;&gt; @app.task(name=&apos;tasks.add&apos;)&gt;&gt;&gt; def add(x, y):... return x + y Contextrequest contains information and state related to the executing task.request的属性 Custom states123456@app.task(bind=True)def upload_files(self, filenames): for i, file in enumerate(filenames): if not self.request.called_directly: self.update_state(state=&apos;PROGRESS&apos;, meta=&#123;&apos;current&apos;: i, &apos;total&apos;: len(filenames)&#125;) Designing Workflows]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ学习--基本概念(1)]]></title>
    <url>%2F2016%2F03%2F09%2Ftool%2F2016_03_09_rabbitmq%E5%AD%A6%E4%B9%A0(1)--%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[RabbitMQ学习–基本概念消息通信概念AMQP信道是基于TCP连接的虚拟连接,每个信道都有一个ID,发布消息,订阅队列,接受消息等AMQP命令都是通过信道发送出去的. AMQP元素 交换器direct如果路由键匹配的话,消息就被投递到对应的队列.有点类似单播. fanout这个类似广播 topic这个类似组播 headers队列绑定虚拟主机消息持久化]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTFul中的基本概念]]></title>
    <url>%2F2015%2F12%2F31%2FHTTP%2F2015_12_31_restful%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[RESRFul中的基本概念Resources 资源可以说这是RESTFul中最基本的概念了。 A resource is an object with a type, associated data, relationships to other resources, and a set of methods that operate on it. It is similar to an object instance in an object-oriented programming language, with the important difference that only a few standard methods are defined for the resource (corresponding to the standard HTTP GET, POST, PUT and DELETE methods), while an object instance typically has many methods. 资源是一个对象(拥有类型，相关联的数据，关系到其他资源，和一组在其上进行操作的方法)。资源很类是与面向对象语言中的对象实例，但是资源只有几个方法可以使用。 Resource DataApplication DataREST MetadataOther DataRepresentations 代表Content-Type]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下搭建openvpn]]></title>
    <url>%2F2015%2F12%2F22%2Ftool%2F2015_12_22_ubuntu%E4%B8%8B%E6%90%AD%E5%BB%BAopenvpn%2F</url>
    <content type="text"><![CDATA[ubuntu下搭建openvpn安装1sudo apt-get -y install openvpn easy-rsa dnsmasqS 生成证书和私钥]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[前端代码-yeoman-bower-gulp]]></title>
    <url>%2F2015%2F12%2F15%2Ffront-end%2F2015_12_15_%E5%89%8D%E7%AB%AF%E4%BB%A3%E7%A0%81-yeoman-bower-gulp%2F</url>
    <content type="text"><![CDATA[工具codekitfis grunt Build tool构建工具类似的有ant gmake等 NodeJSgrunt依赖NodeJS 1npm install -g grunt-cli package.json中的~和^，版本更新的控制 yo 使用yeoman来生成项目的文件，代码结构。 yeoman自动将最佳实践和工具整合进来，大大加速和方便 1npm install -g yo 依赖Node.js 安装模板生成器123npm install -g generator-webappornpm install -g generator-angular 生成1yo angular or 1yo angular --coffee 在Angular中 1234$ yo angular:controller myController$ yo angular:directive myDirective$ yo angular:filter myFilter$ yo angular:service myService 查看已经安装的模板生成器 npm ls -g –depth=1 2&gt;/dev/null | grep generator- bower安装123npm install -g bowerbower installbower install xxx --save bower安装github上的应用12bower install jquery/jquerybower install https://xxx.xx.git 通过url安装直接bower install 地址 bower的两个配置文件bower.json bowerrc 123456&#123; "directory": "bower_components", "proxy": "http://.com", "https-proxy": "https://...", "timeout": 6666&#125; gruntBuild tool 3个 概念 Task Options Target 安装1npm install -g grunt-cli gulp中文官方API 启用一个默认的任务12345var gulp = require(&quot;gulp&quot;)gulp.task(&apos;default&apos;, function() &#123; console.log(&quot;I have configured a gulpfile&quot;)&#125;) webpack相对于gulp,webpack更加高级,关注的是web发布的逻辑构建,二gulp(grunt)是从底层构建 webpack的配置文件.webpack.config.js入口文件1234entry: [ &apos;webpack/hot/only-dev-server&apos;, &apos;./src/components/GalleryByReactApp.js&apos;] 出口文件1234output: &#123; filename: &apos;main.js&apos; publicPath: &apos;/assets/&apos;&#125; resolve: 模块解析配置项alias的好处是:require(“…/src/style/main.css”)可以简写成require(“styles/main.css”)123456resolve: &#123; extensions: [&apos;&apos;, &apos;.js&apos;, &apos;.jsx&apos;], alias: &#123; &apos;styles&apos;: __dirname + &apos;/src/styles&apos; &#125;&#125; webpack的loader机制, loaders autoprefixerloader解决不同浏览器兼容CSS的问题.]]></content>
      <categories>
        <category>Front-End</category>
      </categories>
      <tags>
        <tag>yeoman</tag>
        <tag>bower</tag>
        <tag>gulp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[装饰器]]></title>
    <url>%2F2015%2F12%2F14%2Fpython%2F2015_12_14_%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[装饰器装饰器是在python2.4之后新加入的. 如果没有装饰器12345678910111213#!/usr/bin/env python#coding:utf-8class WhatFor(object): def it(cls): print 'work with %s' % cls it = classmethod(it) def uncommon(): print 'I could be a global function'WhatFor.it()# WhatFor.uncommon() 自定义的装饰器12345def mydecorator(function): def _mydecorator(): return function(*args, **kw) return _mydecorator 测试代码运行时间的装饰器 12345678910111213141516import timedef mydecorator(function): def _mydecorator(*args, **kw): start = time.time() res = function(*args, **kw) print time.time() - start return res return _mydecorator# foo = mydecorator(foo)@mydecoratordef foo(): print 2**128foo() 如何去掉装饰器的效果123456789101112131415161718def mydecorator(function): @wraps(function) def _mydecorator(*args, **kw): start = time.time() res = function(*args, **kw) print(time.time() - start) return res return _mydecorator# foo = mydecorator(foo)@mydecoratordef foo(): print(2**128)foo()orig_foo = foo.__wrapped__orig_foo() 上面这个貌似在py3.x才生效 让装饰器带上参数装饰器带上参数,需要在多加一层包裹的函数.12345678910#!/usr/bin/env python#coding: utf-8def mydecorator(arg1, arg2): def _mydecorator(function): def __mydecorator(*args, **kw): # you can check the args before the function res = function(*args, **kw) return __mydecorator return _mydecorator 装饰器的应用场景参数检查缓存关于与内部状态而不影响输出的函数,这种编程风格是函数型编程的重要特性.缓存装饰器可以讲输出与计算它所需要的参数放在一起.也称为自动缓存,这个在递归的时候,很常用.有的也成为自动缓存或者是动态编程等. 代理上下文提供者]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迭代器和生成器]]></title>
    <url>%2F2015%2F12%2F03%2Fpython%2F2015_12_03_%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[迭代器和生成器最简单实现的一个迭代器.12345678910#!/usr/bin/env python#coding:utf-8items = [1, 2, 3]it = iter(items)print next(it)print next(it)print next(it)print next(it) output12345678python iter_and_generate.py123Traceback (most recent call last): File "iter_and_generate.py", line 10, in &lt;module&gt; print next(it)StopIteration 自定义迭代器只需要一个具有next方法的类,只要能够提供返回迭代器实例的__iter__特殊方法 12345678910111213class MyIterator(object): def __init__(self, step): self.step = step def next(self): if self.step == 0: raise StopIteration self.step -= 1 return self.step def __iter__(self): return selffor el in MyIterator(4): print el itertools模块中好玩的迭代器islice:窗口迭代器12345678910#!/usr/bin/env python#coding:utf-8import itertoolsdef starting_at_five(): value = raw_input().strip() while value != '': for el in itertools.islice(value.split(), 4, None): yield el value = raw_input().strip() tee:往返式的迭代器123def with_head(iterable, headsize=1): a, b = itertools.tee(iterable) return list(itertools.islice(a, headsize)), b groupby:uniq迭代器使用行程长度编码(RLF)来压缩数据1234567from itertools import groupbydef compress(data): reutrn ((len(list(group)), name) \ for name, group in groupby(data)def decompress(data): return (car * size for size, car in data) 生成器使得函数需要返回一系列元素的函数变得更加简单,高效. Ex 1234567891011#!/usr/bin/env python#coding:utf-8def fibonacci(): a, b = 0, 1 while True: yield b a, b = b, a+bfib = fibonacci()# print fib.next()print [fib.next() for i in range(10)] 在处理大的文件的时候，这种方式比较节省内存 关于yield,以及yeild更多姿势12345678910111213141516171819202122#!/usr/bin/env python#coding:utf-8def psychologist(): print "请告诉我你的问题？" while True: answer = (yield) if answer is not None: if answer.endswith('?'): print("不要想太多问题") elif "good" in answer: print("A that\'s good, go on") elif 'bad' in answer: print("Don'\t be so negative")free = psychologist()free.next()free.next()free.next()free.send("why I show?")free.send("good")free.send("bad") send()的工作机制和next（）一样。但是yield将变成能够返回传入的值。 在python3.x中，yield有更多的用法。]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python面向对象--继承]]></title>
    <url>%2F2015%2F12%2F03%2Fpython%2F2015_12_03_python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1--%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[python面向对象–继承(MRO)最近觉得py的基础还是有必要再看一下的。 python的多继承的属性继承搜索Python在处理多继承时同名函数，如果处理呢？ Ex 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/ben/env python#coding:utf-8# __metaclass__ = typeclass A(object): def foo(self): print "A-foo" def bar(self): print "A-bar"class B(object): def foo(self): print "B-foo" def bar(self): print "B-bar"class AA(A): def bar(self): print "AA-bar"class BB(B): def foo(self): print "BB-bar"class C(AA, BB): passc = C()c.foo()c.bar()class P1: def foo(self): print "p1-foo"class P2: def foo(self): print "p2-foo" def bar(self): print "p2-bar"class C1(P1, P2): passclass C2(P1, P2): def bar(self): print "C2-bar"class D(C1, C2): passprint D.__mro__d = D();d.foo()d.bar()cc = CC()cc.show() 在经典类中输出如下:output 1234A-fooAA-barp1-foop2-bar 在新类中输出如下:output 1234A-fooAA-barp1-fooC2-bar 很明显的是,在老式的py类(py2.3以前的版本或者在py2.3+之后的版本中没有显示声明)中,依据的是从左到右,深度优先的规则.然而在新式类中,采用的是另外一套规则.所以在代码中混合新式类和旧式类,在MRO中会有不用的表现 使用类的__mro__属性可以得到一个可读的查找顺序表 mro即method resolution order，主要用于在多继承时判断调的属性的路径(来自于哪个类)。python在2.3中使用的是C3算法. python 需要对其进行线性化(C3 Linearization),将继承图关系线性化。通过线性化，再依次查找类方法，直至找到该方法为止。线性化算法是python多继承的核心部分。线性化过程中，必须满足两个性质: 单调性 一致性直接父类的顺序通过用户来声明，父类线性化的顺序为从左到右。在进行线性化归并过程中，一致性主要保证类的局部优先级顺序，它定义了两个变量: python多重继承python在多重继承中的问题?来看&lt;&gt;中的栗子 12345678910111213141516171819202122232425#!/usr/ben/env python#coding:utf-8# __metaclass__ = typeclass Brid: def __init__(self): self.hungry = True def eat(self): if self.hungry: print "Aaaah..." self.hungry = False else: print 'No, thanks'class SongBrid(Brid): def __init__(self): self.sound = 'Squawk' def sing(self): print self.soundsb = SongBrid()sb.sing()sb.eat() 结果报错,输出如下: 1234567SquawkTraceback (most recent call last): File "inherit_2.py", line 25, in &lt;module&gt; sb.eat() File "inherit_2.py", line 10, in eat if self.hungry:AttributeError: SongBrid instance has no attribute 'hungry' why? 因为在SongBrid中,构造方法被重写.所以找不到属性了 解决方法: 1:调用未绑定的超类构造方法. 123456class SongBrid(Brid): def __init__(self): Brid.__init__(self) self.sound = 'Squawk' def sing(self): print self.sound 2:使用super函数(新式类才可以这么做) 123456lass SongBrid(Brid): def __init__(self): super(SongBrid, self).__init__() self.sound = 'Squawk' def sing(self): print self.sound super()类还是方法?打印了以下super()的类型,发现类型是 Super的缺陷基类中的__init__不会被显示调用,所以需要开发人员调用. 混用super和传统调用123456789101112131415161718192021#!/usr/bin/env python#coding:utf-8class A(object): def __init__(self): print &quot;A&quot; super(A, self).__init__()class B(object): def __init__(self): print &quot;B&quot; super(B, self).__init__()class C(A, B): def __init__(self): print &quot;C&quot; A.__init__(self) # 传统调用 B.__init__(self)print &quot;MRO:&quot;, [x.__name__ for x in C.__mro__]C() output: 12345MRO: [&apos;C&apos;, &apos;A&apos;, &apos;B&apos;, &apos;object&apos;]CABB 可以看到,当C实例调用A.__init__(self),因为super(A, self).init()将调用B的构造程序. 不同类型的参数123456789101112131415161718192021class BaseBase(object): def __init__(self): print &quot;basebase&quot; super(BaseBase, self).__init__()class Base1(BaseBase): def __init__(self): print &quot;base1&quot; super(Base1, self).__init__()class Base2(BaseBase): def __init__(self, arg): print &apos;base2&apos; super(Base2, self).__init__(arg)class MyClass(Base1, Base2): def __init__(self): print &quot;my base&quot; super(MyClass, self).__init__()m = MyClass(10) 一种解决方式,就是给所有的init(self), 替换成init(self, args, *kw) 最佳实践 减少使用多继承 super不能混用 检查MRO]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>mro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用virtualenv来管理python运行环境]]></title>
    <url>%2F2015%2F11%2F19%2Fpython%2F2015_11_19_%E5%88%A9%E7%94%A8virtualenv%E6%9D%A5%E7%AE%A1%E7%90%86python%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[virtualenv的安装和运行都很简单，因为之前一直使用的pyenv，所以这个工具都没怎么用过，只是记录一下命令 12345virtualenv ENVsource bin/activate$ deactivate 使用的方法非常简单]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在RESTFul中基于Token的认证]]></title>
    <url>%2F2015%2F11%2F19%2FHTTP%2F2015_11_19_%E5%9C%A8restful%E4%B8%AD%E5%9F%BA%E4%BA%8Etoken%E7%9A%84%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[在RESTFul中使用Token来进行身份认证用户只登录一次下次访问的时候使用cookie而不是username或者是密码 失效 1234567curl -c c.txt \ http://localhost:8080/api/v1/login \ -u user1:pass1curl -b c.txt \ --data '&#123;titl...&#125;' \ http://localhost:8080/api/v1/poems logging in 12345def GET(self): user = require_authenticated_user( self.db) token = generate_token() self.db.tokens[tooken] = &#123;&quot;user&quot;: user&#125;]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>restful</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pelican和Github建博客]]></title>
    <url>%2F2015%2F11%2F19%2FMISC%2F2015_11_19_pelican%E5%92%8Cgithub%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[使用Pelican和Github来搭建博客系统关于博客之前所有的东西都记录在了印象笔记上，可以没有免费的markdown的插件，印象笔记对于记录一些东西来说还不错,不过对于写些东西,感觉还需要一些额外的东西.后来发现这套解决方案还是不错滴！用atom来编辑，下载一些能够预览markdown的插件效果还是蛮不错滴，同步在github上，在哪都可以编辑修改。 关于github Pagegithub Page官方地址 关于Pelican具体请见Pelican文档 Pelican的主题可以很方便的更换主题，只需在配置文件里面简单的修改就好了 Pelican的插件Pelican的插件有很多 LaTex支持LaTex主要是比较方便的来写数学公式首先是配置上, 需要加上render_math的插件：其实用的就是MathJax.js 12PLUGIN_PATHS = ['pelican-plugins']PLUGINS = ['render_math', 'sitemap', 'autopages', 'subcategory' ] 接下来比较重要的,也就是比较核心的操作就是,在主题templates/bash.html下的head标签之前加上 123456789101112&lt;script type="text/x-mathjax-config"&gt; MathJax.Hub.Config(&#123; "HTML-CSS": &#123; styles: &#123; ".MathJax .mo, .MathJax .mi": &#123;color: "black ! important"&#125;&#125; &#125;, tex2jax: &#123;inlineMath: [['$','$'], ['\\(','\\)']],processEscapes: true&#125; &#125;); &lt;/script&gt; &lt;script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"&gt;&lt;/script&gt;&lt;/head&gt; $$E=mc^2$$ Latex数学符号清参见Latex数学公式 评论的支持静态博客要支持评论,可以使用disqus.第一步,你只需要注册一个disqus帐.第二部,需要设置DISQUS_SITENAME1234SITEURL = &apos;http://fsxchen.github.io&apos;DISQUS_SITENAME = u&quot;coucou-blog&quot;RELATIVE_URLS = False 搞定 使用Atom编辑博客图片上传写博客,必须能上传图片嘛,图片得在atom这个编辑器上下功夫,原先的模块,用的是以下模块:markclip qiniu-puloader markdown-assistant,本来后面两个应该是可以的,但是在我的大Ubuntu下就是无法使用.所有在github上找了不少,后来把这三个的代码相互改了改,就可以用了,具体办法就是在markclip的配置中,增加一个七牛的配置. Tips用下面的这个函数，一条命令就搞定了。当然需要fabirc以及fabfile.py只需要执行fab public 123456# @hosts(production)def publish(): &quot;&quot;&quot;Publish to production via rsync&quot;&quot;&quot; local(&apos;git add .&apos;) local(&apos;git commit) local(&apos;git push -f origin master&apos;) 自动同步output下的到gh-pages,可以编辑.git/pooks/post-commit: 12chmod a+x post-commitpelican content -o output -s pelicanconf.py &amp;&amp; ghp-import output &amp;&amp; git push -f origin gh-pages:master]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Pelican</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树]]></title>
    <url>%2F2014%2F11%2F19%2Fmachinelearning%2F2014-12-09-%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[决策树决策数的构造熵和信息增益​ 划分数据集的大原则是：将无序的数据变得更加有序。划分数据的方式有很多种，但是每种都有相应的优缺点。组织杂乱无章数据的一种方式就是使用信息论度量信息。在划分数据集之前之后信息发生的变化称为信息增益.集合信息的度量方式称为香农熵或者简称熵如果待分类的事物可能划分在多个分类之中，则符号$$x_{i}$$的信息定义为 $$l(x{i})=-\log{2}p(x_{i})$$ 其中$$p(x_{i})$$是选择该分类的概率为了计算熵，我们需要计算所有类别所有可能包含值的信息期望值 $$H=-\sum{i=1}^{n}p(x{i})log{2}p(x{i})$$ Eg：计算熵 下面用代码来实现计算数据集合的香农熵 12345678910111213141516from math import logdef calcShannonEnt(dataSet): numEntries = len(dataSet) lableCounts = &#123;&#125; for featVec in dataSet: currentLable = featVec[-1] if currentLable not in lableCounts.keys(): lableCounts[currentLable] = 0 lableCounts[currentLable] += 1 shannonENt = 0.0 for key in lableCounts: prob = float(lableCounts[key])/ numEntries shannonENt = -= prob * log(prob, 2) return shannonENt 熵的计算 计算信息增益 如图所示：计算关于速度的信息增益，因为如果以速度划分，熵为0，由于父数据集的熵为1，所以信息增益为1.这个是一个最好的信息增益，所以应该从这里划分数据集。 在ipython里面找一个集合测试一下： 123456789101112In [1]: import treesIn [2]: myDat, lables = trees.createDataSet()In [3]: myDatOut[3]: [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]In [4]: lablesOut[4]: ['no surfacing', 'flippers']In [5]: trees.calcShannonEnt(myDat)Out[5]: 0.9709505944546686 香农熵的计算还是比较简单的，但是使用比较复杂 划分数据集在前面介绍了如何度量集合的无序程度，这里还需要来划分数据集，然后来度量数据集的熵，来看是否正确的划分了数据集。下面的代码实现了集合的划分 12345678def splitDataSet(dataSet, axis, value): retDataSet = [] for featVec in dataSet: if featVec[axis] == value: reducedFeatVec = featVec[:axis] reducedFeatVec.extend(featVec[axis+1:]) retDataSet.append(reducedFeatVec) return retDataSet 来看一下splitDataSet(dataSet, axis, value)这个函数，需要3个参数：待划分的数据集、划分数据集的特征、需要返回的特征值。 123456789101112In [1]: import treesIn [2]: myDat, labels = trees.createDataSet()In [3]: myDatOut[3]: [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]In [4]: trees.splitDataSet(myDat, 0, 1)Out[4]: [[1, 'yes'], [1, 'yes'], [0, 'no']]In [5]: trees.splitDataSet(myDat, 0, 0)Out[5]: [[1, 'no'], [1, 'no']] 下面 来选择最好的数据划分方式 1234567891011121314151617def chooseBestFeatureToSplit(dataSet): numFeatures = len(dataSet[0]) - 1 baseEntropy = calcShannonEnt(dataSet) bestInfoGain = 0.0; bestFeature = -1 for i in range(numFeatures): featList = [example[i] for example in dataSet] uniqueVals = set(featList) newEntropy = 0.0 for value in uniqueVals: subDataSte = splitDataSet(dataSet, i, value) prob = len(subDataSte) / float(len(dataSet)) newEntropy += prob * calcShannonEnt(subDataSte) infoGain = baseEntropy - newEntropy if (infoGain &gt; bestInfoGain): bestInfoGain = infoGain bestFeature = i return bestFeature 这段代码实现了选取特征，划分数据集，计算得出最好的划分数据集的特征。这样划分的意义所在 id 不浮出水面是否可以生存 是否有脚蹼 属于鱼类 1 是 是 是 2 是 是 是 3 是 否 否 4 否 是 否 5 否 是 否 123456789In [1]: import treesIn [2]: myDat, labels = trees.createDataSet()In [3]: myDatOut[3]: [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]In [4]: trees.chooseBestFeatureToSplit(myDat)Out[4]: 0 通个这个结论，可以看到使用第0个特征是最好的划分方式。结合上表来分析一下。如果按照第一个特征划分数据，则第一组值为1(是)的分一组，否(0)为另一组。‘1’组里面包含两个鱼类和一个非鱼类。‘0’组里面只有非鱼类。 递归构建决策数构建决策树代码如下： 1234567891011121314151617181920212223242526def majorityCnt(classList): classCount = &#123;&#125; for vote in classList: if vote not in classCount.keys(): classCount[vote] = 0 classCount += 1 sortedClassCount = sorted(classCount.iteritems(), \ key=operator.itemgetter(1), reverse=True) return sortedClassCount[0][0]def createTree(dataSet, labels): classList = [example[i] for example in dataSet] if classList.count(classList[0]) == len(classList): return classList[0] if len(dataSet[0]) == 1: return majorityCnt(classList) bestFeat = chooseBestFeatureToSplit(dataSet) bestFeatLabel = labels[bestFeat] myTree = &#123;bestFeatLabel:&#123;&#125;&#125; del(labels[bestFeat]) featValues = [example[bestFeat] for example in dataSet] uniqueVals = set(featValues) for value in uniqueVals: subLabels = labels[:] myTree[bestFeatLabel][value] = createTree(splitDataSet \ (dataSet, bestFeat, value), subLabels) return myTree createTree(dataSet, labels)这个函数有两个参数：数据集和标签列表。递归终止的两个条件：1、所有标签都相同。2、使用完了所有的特征。这里使用了字典来存储了树的信息。 测试和存储分类器测试算法：使用决策树执行分类代码如下： 12345678910def classify(inputTree, featLabels, testVec): firstStr = inputTree.keys()[0] secondDict = inputTree[firstStr] featIndex = featLabels.index(firstStr) for key in secondDict.keys(): if testVec[featIndex] == key: if type(secondDict[key]).__name__ == 'dict': classLabel = classify(secondDict[key], featLabels, testVec) else: classLabel = secondDict[key] return classLabel 使用算法：决策数的存储使用pickle模块存储决策树，序列化对象可以在磁盘上保存对象。并且在需要的时候读取。任何对象都支持序列化操作。 sklearn 决策树分类12345678910111213141516171819In [1]: from sklearn import treeIn [2]: x = [[0,0], [1, 1]]In [3]: y = [0, 1]In [4]: clf = tree.DecisionTreeClassifier( ...: )In [5]: clf.fit(x, y)Out[5]:DecisionTreeClassifier(class_weight=None, criterion=&apos;gini&apos;, max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_split=1e-07, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&apos;best&apos;)In [6]: clf.predict([0,0])Out[6]: array([0]) 调节参数提高准确率min_samples_split 最少分割样本,分割的最小的样本数量 决策树优缺点缺点： 容易过度拟合]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇博客]]></title>
    <url>%2F2014%2F03%2F19%2FFristBlog%2F</url>
    <content type="text"><![CDATA[没事乱写写，技术在于折腾，每天进步一点点!]]></content>
      <categories>
        <category>misc</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
</search>